"""
Survival Analysis System for Credit Risk Assessment
Implements Cox Proportional Hazards, Random Survival Forest, and Kaplan-Meier Estimator
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
import joblib
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

try:
    from lifelines import CoxPHFitter, KaplanMeierFitter
    from lifelines.utils import concordance_index
    LIFELINES_AVAILABLE = True
except ImportError:
    LIFELINES_AVAILABLE = False
    print("Warning: lifelines not installed. Install with: pip install lifelines")

try:
    from sksurv.ensemble import RandomSurvivalForest
    from sksurv.util import Surv
    SKSURV_AVAILABLE = True
except ImportError:
    SKSURV_AVAILABLE = False
    print("Warning: scikit-survival not installed. Install with: pip install scikit-survival")


class SurvivalAnalysisSystem:
    """
    H·ªá th·ªëng ph√¢n t√≠ch s·ªëng s√≥t cho ƒë√°nh gi√° r·ªßi ro t√≠n d·ª•ng
    D·ª± b√°o th·ªùi gian ƒë·∫øn khi doanh nghi·ªáp v·ª° n·ª£ (Time-to-Default)
    """

    def __init__(self):
        self.cox_model = None
        self.rsf_model = None
        self.km_fitter = None
        self.feature_names = [
            'X_1', 'X_2', 'X_3', 'X_4', 'X_5', 'X_6', 'X_7',
            'X_8', 'X_9', 'X_10', 'X_11', 'X_12', 'X_13', 'X_14'
        ]
        self.feature_name_mapping = {
            'X_1': 'Bi√™n l·ª£i nhu·∫≠n g·ªôp',
            'X_2': 'Bi√™n l·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø',
            'X_3': 'ROA',
            'X_4': 'ROE',
            'X_5': 'H·ªá s·ªë n·ª£ tr√™n t√†i s·∫£n',
            'X_6': 'H·ªá s·ªë n·ª£ tr√™n VCSH',
            'X_7': 'Kh·∫£ nƒÉng thanh to√°n hi·ªán h√†nh',
            'X_8': 'Kh·∫£ nƒÉng thanh to√°n nhanh',
            'X_9': 'Kh·∫£ nƒÉng tr·∫£ l√£i',
            'X_10': 'Kh·∫£ nƒÉng tr·∫£ n·ª£ g·ªëc',
            'X_11': 'Kh·∫£ nƒÉng t·∫°o ti·ªÅn/VCSH',
            'X_12': 'V√≤ng quay h√†ng t·ªìn kho',
            'X_13': 'K·ª≥ thu ti·ªÅn b√¨nh qu√¢n',
            'X_14': 'Hi·ªáu su·∫•t s·ª≠ d·ª•ng t√†i s·∫£n'
        }
        self.training_data = None
        self.metrics = {}

    def prepare_data(self, df: pd.DataFrame, duration_col: str = 'months_to_default',
                    event_col: str = 'event') -> Tuple[pd.DataFrame, np.ndarray, np.ndarray]:
        """
        Chu·∫©n b·ªã d·ªØ li·ªáu cho survival analysis

        Args:
            df: DataFrame ch·ª©a 14 ch·ªâ s·ªë t√†i ch√≠nh + months_to_default + event
            duration_col: T√™n c·ªôt th·ªùi gian (th√°ng)
            event_col: T√™n c·ªôt event (1=v·ª° n·ª£, 0=censored)

        Returns:
            X: Features DataFrame
            durations: Array th·ªùi gian
            events: Array events
        """
        # L·∫•y 14 ch·ªâ s·ªë t√†i ch√≠nh
        X = df[self.feature_names].copy()

        # X·ª≠ l√Ω missing values
        X = X.fillna(X.median())

        # L·∫•y duration v√† event
        durations = df[duration_col].values
        events = df[event_col].values if event_col in df.columns else np.ones(len(df))

        # ƒê·∫£m b·∫£o duration > 0
        durations = np.maximum(durations, 0.1)

        return X, durations, events

    def train_cox_model(self, df: pd.DataFrame, duration_col: str = 'months_to_default',
                       event_col: str = 'event') -> Dict[str, Any]:
        """
        Hu·∫•n luy·ªán Cox Proportional Hazards Model

        Args:
            df: Training data v·ªõi 14 ch·ªâ s·ªë + months_to_default + event

        Returns:
            Dict ch·ª©a metrics v√† model info
        """
        if not LIFELINES_AVAILABLE:
            raise ImportError("lifelines package is required. Install with: pip install lifelines")

        # Chu·∫©n b·ªã d·ªØ li·ªáu
        X, durations, events = self.prepare_data(df, duration_col, event_col)

        # T·∫°o DataFrame cho Cox model
        cox_data = X.copy()
        cox_data['duration'] = durations
        cox_data['event'] = events

        # Hu·∫•n luy·ªán Cox model
        self.cox_model = CoxPHFitter(penalizer=0.01)
        self.cox_model.fit(cox_data, duration_col='duration', event_col='event')

        # T√≠nh C-index (concordance index)
        c_index = self.cox_model.concordance_index_

        # L∆∞u training data ƒë·ªÉ d√πng cho Kaplan-Meier baseline
        self.training_data = cox_data

        # L∆∞u metrics
        self.metrics['cox_c_index'] = float(c_index)
        self.metrics['cox_log_likelihood'] = float(self.cox_model.log_likelihood_)

        return {
            'model_type': 'Cox Proportional Hazards',
            'c_index': float(c_index),
            'log_likelihood': float(self.cox_model.log_likelihood_),
            'trained_at': datetime.now().isoformat(),
            'n_samples': len(df),
            'n_features': len(self.feature_names)
        }

    def train_random_survival_forest(self, df: pd.DataFrame,
                                     duration_col: str = 'months_to_default',
                                     event_col: str = 'event',
                                     n_estimators: int = 100) -> Dict[str, Any]:
        """
        Hu·∫•n luy·ªán Random Survival Forest

        Args:
            df: Training data
            n_estimators: S·ªë l∆∞·ª£ng trees

        Returns:
            Dict ch·ª©a metrics
        """
        if not SKSURV_AVAILABLE:
            raise ImportError("scikit-survival required. Install with: pip install scikit-survival")

        # Chu·∫©n b·ªã d·ªØ li·ªáu
        X, durations, events = self.prepare_data(df, duration_col, event_col)

        # T·∫°o structured array cho scikit-survival
        y = Surv.from_arrays(event=events.astype(bool), time=durations)

        # Hu·∫•n luy·ªán RSF
        self.rsf_model = RandomSurvivalForest(
            n_estimators=n_estimators,
            min_samples_split=10,
            min_samples_leaf=5,
            max_features="sqrt",
            n_jobs=-1,
            random_state=42
        )
        self.rsf_model.fit(X, y)

        # T√≠nh C-index
        c_index = self.rsf_model.score(X, y)

        # L∆∞u metrics
        self.metrics['rsf_c_index'] = float(c_index)
        self.metrics['rsf_n_estimators'] = n_estimators

        return {
            'model_type': 'Random Survival Forest',
            'c_index': float(c_index),
            'n_estimators': n_estimators,
            'trained_at': datetime.now().isoformat(),
            'n_samples': len(df),
            'n_features': len(self.feature_names)
        }

    def calculate_kaplan_meier(self, df: pd.DataFrame = None,
                              duration_col: str = 'months_to_default',
                              event_col: str = 'event') -> Dict[str, Any]:
        """
        T√≠nh Kaplan-Meier Estimator (baseline survival function)

        Args:
            df: Data (n·∫øu None, d√πng training data)

        Returns:
            Dict v·ªõi survival function v√† timeline
        """
        if not LIFELINES_AVAILABLE:
            raise ImportError("lifelines package required")

        # S·ª≠ d·ª•ng training data n·∫øu kh√¥ng c√≥ df
        if df is None:
            if self.training_data is None:
                raise ValueError("No training data available. Train Cox model first.")
            durations = self.training_data['duration'].values
            events = self.training_data['event'].values
        else:
            _, durations, events = self.prepare_data(df, duration_col, event_col)

        # Fit Kaplan-Meier
        self.km_fitter = KaplanMeierFitter()
        self.km_fitter.fit(durations, events)

        # L·∫•y survival function
        timeline = self.km_fitter.survival_function_.index.tolist()
        survival_probs = self.km_fitter.survival_function_['KM_estimate'].tolist()

        # T√≠nh median survival time
        median_survival = self.km_fitter.median_survival_time_

        return {
            'timeline': timeline,
            'survival_probabilities': survival_probs,
            'median_survival_time': float(median_survival) if not np.isnan(median_survival) else None,
            'event_count': int(events.sum()),
            'censored_count': int((1 - events).sum())
        }

    def predict_survival_curve(self, indicators: Dict[str, float],
                               model_type: str = 'cox',
                               timeline: Optional[List[float]] = None) -> Dict[str, Any]:
        """
        D·ª± b√°o survival curve cho m·ªôt doanh nghi·ªáp m·ªõi

        Args:
            indicators: Dict v·ªõi 14 ch·ªâ s·ªë t√†i ch√≠nh (X_1 ƒë·∫øn X_14)
            model_type: 'cox' ho·∫∑c 'rsf'
            timeline: List c√°c th·ªùi ƒëi·ªÉm (th√°ng) ƒë·ªÉ d·ª± b√°o

        Returns:
            Dict v·ªõi survival probabilities t·∫°i c√°c th·ªùi ƒëi·ªÉm
        """
        # T·∫°o DataFrame t·ª´ indicators
        X_new = pd.DataFrame([indicators])[self.feature_names]

        # X·ª≠ l√Ω missing values
        X_new = X_new.fillna(0)

        if model_type == 'cox':
            if self.cox_model is None:
                raise ValueError("Cox model not trained. Call train_cox_model() first.")

            # D·ª± b√°o survival function
            surv_func = self.cox_model.predict_survival_function(X_new)

            # L·∫•y survival curve c·ªßa sample ƒë·∫ßu ti√™n (c·ªôt ƒë·∫ßu ti√™n, kh√¥ng ph·∫£i row ƒë·∫ßu ti√™n)
            surv_curve = surv_func.iloc[:, 0]  # Series v·ªõi index = timeline

            # N·∫øu kh√¥ng c√≥ timeline, d√πng timeline t·ª´ model
            if timeline is None:
                timeline = surv_curve.index.tolist()
                survival_probs = [float(p) for p in surv_curve.values.tolist()]
            else:
                # L·∫•y survival probabilities t·∫°i c√°c th·ªùi ƒëi·ªÉm c·ª• th·ªÉ
                survival_probs = []
                for t in timeline:
                    if t in surv_curve.index:
                        survival_probs.append(float(surv_curve.loc[t]))
                    else:
                        # Interpolate n·∫øu th·ªùi ƒëi·ªÉm kh√¥ng c√≥ trong index
                        idx = np.searchsorted(surv_curve.index, t)
                        if idx == 0:
                            survival_probs.append(float(surv_curve.iloc[0]))
                        elif idx >= len(surv_curve):
                            survival_probs.append(float(surv_curve.iloc[-1]))
                        else:
                            # Linear interpolation
                            t1, p1 = surv_curve.index[idx-1], surv_curve.iloc[idx-1]
                            t2, p2 = surv_curve.index[idx], surv_curve.iloc[idx]
                            prob = p1 + (t - t1) * (p2 - p1) / (t2 - t1)
                            survival_probs.append(float(prob))

        elif model_type == 'rsf':
            if self.rsf_model is None:
                raise ValueError("RSF model not trained. Call train_random_survival_forest() first.")

            # D·ª± b√°o survival function
            surv_funcs = self.rsf_model.predict_survival_function(X_new, return_array=True)

            # L·∫•y survival probabilities c·ªßa sample ƒë·∫ßu ti√™n
            surv_probs_array = surv_funcs[0]  # Array survival probs c·ªßa sample ƒë·∫ßu ti√™n
            unique_times = self.rsf_model.unique_times_

            # Timeline t·ª´ RSF model
            if timeline is None:
                timeline = unique_times.tolist()
                survival_probs = [float(p) for p in surv_probs_array.tolist()]
            else:
                # L·∫•y survival probabilities t·∫°i c√°c th·ªùi ƒëi·ªÉm c·ª• th·ªÉ
                survival_probs = []
                for t in timeline:
                    idx = np.searchsorted(unique_times, t)
                    if idx == 0:
                        survival_probs.append(float(surv_probs_array[0]))
                    elif idx >= len(unique_times):
                        survival_probs.append(float(surv_probs_array[-1]))
                    elif t == unique_times[idx]:
                        survival_probs.append(float(surv_probs_array[idx]))
                    else:
                        # Linear interpolation
                        t1, p1 = unique_times[idx-1], surv_probs_array[idx-1]
                        t2, p2 = unique_times[idx], surv_probs_array[idx]
                        prob = p1 + (t - t1) * (p2 - p1) / (t2 - t1)
                        survival_probs.append(float(prob))
        else:
            raise ValueError(f"Unknown model_type: {model_type}. Use 'cox' or 'rsf'.")

        return {
            'timeline': timeline,
            'survival_probabilities': survival_probs,
            'model_type': model_type
        }

    def calculate_median_time_to_default(self, indicators: Dict[str, float],
                                         model_type: str = 'cox') -> float:
        """
        T√≠nh median time-to-default cho m·ªôt doanh nghi·ªáp

        Args:
            indicators: Dict v·ªõi 14 ch·ªâ s·ªë
            model_type: 'cox' ho·∫∑c 'rsf'

        Returns:
            Median time (th√°ng)
        """
        # D·ª± b√°o survival curve
        result = self.predict_survival_curve(indicators, model_type)

        timeline = result['timeline']
        survival_probs = result['survival_probabilities']

        # Ki·ªÉm tra timeline v√† survival_probs c√≥ d·ªØ li·ªáu
        if not timeline or not survival_probs:
            raise ValueError("Timeline ho·∫∑c survival probabilities r·ªóng")

        # T√¨m th·ªùi ƒëi·ªÉm m√† survival probability = 0.5
        for i, prob in enumerate(survival_probs):
            if prob <= 0.5:
                if i == 0:
                    return float(timeline[0])
                else:
                    # Linear interpolation
                    t1, p1 = timeline[i-1], survival_probs[i-1]
                    t2, p2 = timeline[i], survival_probs[i]

                    # Tr√°nh chia cho 0
                    if abs(p2 - p1) < 1e-10:
                        median_time = t1
                    else:
                        median_time = t1 + (0.5 - p1) * (t2 - t1) / (p2 - p1)
                    return float(median_time)

        # N·∫øu survival probability kh√¥ng bao gi·ªù xu·ªëng d∆∞·ªõi 0.5
        # Doanh nghi·ªáp c√≥ r·ªßi ro th·∫•p, median time r·∫•t l·ªõn
        return float(timeline[-1])  # Return max time

    def get_hazard_ratios(self, top_k: int = 5) -> List[Dict[str, Any]]:
        """
        L·∫•y hazard ratios t·ª´ Cox model (top K ch·ªâ s·ªë quan tr·ªçng nh·∫•t)

        Args:
            top_k: S·ªë l∆∞·ª£ng ch·ªâ s·ªë mu·ªën l·∫•y

        Returns:
            List c√°c dict v·ªõi feature name, hazard ratio, v√† p-value
        """
        if self.cox_model is None:
            raise ValueError("Cox model not trained. Call train_cox_model() first.")

        # L·∫•y hazard ratios v√† p-values
        hazard_ratios = np.exp(self.cox_model.params_)  # exp(coef) = hazard ratio
        p_values = self.cox_model.summary['p']
        confidence_intervals = self.cox_model.confidence_intervals_

        # T·∫°o list k·∫øt qu·∫£
        results = []
        for feature in self.feature_names:
            if feature in hazard_ratios.index:
                results.append({
                    'feature_code': feature,
                    'feature_name': self.feature_name_mapping[feature],
                    'hazard_ratio': float(hazard_ratios[feature]),
                    'coefficient': float(self.cox_model.params_[feature]),
                    'p_value': float(p_values[feature]),
                    'ci_lower': float(confidence_intervals.loc[feature].iloc[0]),
                    'ci_upper': float(confidence_intervals.loc[feature].iloc[1]),
                    'significance': 'C√≥ √Ω nghƒ©a' if p_values[feature] < 0.05 else 'Kh√¥ng c√≥ √Ω nghƒ©a'
                })

        # S·∫Øp x·∫øp theo absolute hazard ratio (c√†ng xa 1.0 c√†ng quan tr·ªçng)
        results.sort(key=lambda x: abs(np.log(x['hazard_ratio'])), reverse=True)

        return results[:top_k]

    def get_individual_risk_contributions(self, indicators: Dict[str, float],
                                         top_k: int = 5) -> List[Dict[str, Any]]:
        """
        T√≠nh risk contribution c·ªßa T·ª™NG CH·ªà S·ªê cho DOANH NGHI·ªÜP C·ª§ TH·ªÇ n√†y
        (KH√ÅC v·ªõi get_hazard_ratios - tr·∫£ v·ªÅ model-level metrics gi·ªëng nhau cho m·ªçi DN)

        Args:
            indicators: Dict v·ªõi 14 ch·ªâ s·ªë t√†i ch√≠nh c·ªßa doanh nghi·ªáp C·ª§ TH·ªÇ
            top_k: S·ªë l∆∞·ª£ng ch·ªâ s·ªë mu·ªën l·∫•y

        Returns:
            List c√°c dict v·ªõi feature name, contribution, v√† di·ªÖn gi·∫£i C·ª§ TH·ªÇ cho DN n√†y

        V√≠ d·ª•:
            - DN A (ROA = 10%): X_3 contribution = -2.5 (gi·∫£m r·ªßi ro)
            - DN B (ROA = -5%): X_3 contribution = +1.8 (tƒÉng r·ªßi ro)
        """
        if self.cox_model is None:
            raise ValueError("Cox model not trained. Call train_cox_model() first.")

        # T·∫°o DataFrame cho doanh nghi·ªáp n√†y
        company_data = pd.DataFrame([indicators])

        # ƒê·∫£m b·∫£o c√≥ ƒë·ªß 14 ch·ªâ s·ªë
        for feature in self.feature_names:
            if feature not in company_data.columns:
                company_data[feature] = 0

        # S·∫Øp x·∫øp theo th·ª© t·ª± features
        company_data = company_data[self.feature_names]

        # X·ª≠ l√Ω missing values
        company_data = company_data.fillna(0)

        # L·∫•y coefficients t·ª´ Cox model
        coefficients = self.cox_model.params_
        p_values = self.cox_model.summary['p']

        # T√≠nh training data statistics (mean) ƒë·ªÉ so s√°nh
        if self.training_data is not None:
            training_means = self.training_data[self.feature_names].mean()
            training_stds = self.training_data[self.feature_names].std()
        else:
            training_means = pd.Series(0, index=self.feature_names)
            training_stds = pd.Series(1, index=self.feature_names)

        # T√≠nh risk contributions cho DOANH NGHI·ªÜP N√ÄY
        results = []
        total_log_hazard = 0

        for feature in self.feature_names:
            if feature in coefficients.index:
                coef = float(coefficients[feature])
                company_value = float(company_data[feature].iloc[0])
                mean_value = float(training_means[feature])
                std_value = float(training_stds[feature])
                p_val = float(p_values[feature])

                # Risk contribution = coef √ó (value - mean)
                # Positive contribution = TƒÇNG r·ªßi ro
                # Negative contribution = GI·∫¢M r·ªßi ro
                contribution = coef * (company_value - mean_value)
                total_log_hazard += contribution

                # Standardized contribution (so v·ªõi ƒë·ªô l·ªách chu·∫©n)
                if std_value > 0:
                    z_score = (company_value - mean_value) / std_value
                    contribution_std = coef * z_score
                else:
                    z_score = 0
                    contribution_std = 0

                # Di·ªÖn gi·∫£i
                if abs(contribution) < 0.01:
                    interpretation = "‚ö™ Kh√¥ng ·∫£nh h∆∞·ªüng (g·∫ßn trung b√¨nh)"
                elif contribution > 0:
                    # TƒÇNG r·ªßi ro
                    if contribution > 1.0:
                        interpretation = f"üî¥ TƒÇNG r·ªßi ro M·∫†NH (+{contribution:.2f})"
                    elif contribution > 0.5:
                        interpretation = f"üü† TƒÇNG r·ªßi ro TRUNG B√åNH (+{contribution:.2f})"
                    else:
                        interpretation = f"üü° TƒÉng r·ªßi ro nh·∫π (+{contribution:.2f})"
                else:
                    # GI·∫¢M r·ªßi ro
                    if contribution < -1.0:
                        interpretation = f"üü¢ GI·∫¢M r·ªßi ro M·∫†NH ({contribution:.2f})"
                    elif contribution < -0.5:
                        interpretation = f"üü¢ GI·∫¢M r·ªßi ro TRUNG B√åNH ({contribution:.2f})"
                    else:
                        interpretation = f"üü¢ Gi·∫£m r·ªßi ro nh·∫π ({contribution:.2f})"

                # So s√°nh v·ªõi trung b√¨nh
                if company_value > mean_value:
                    comparison = f"CAO h∆°n TB {abs(company_value - mean_value):.3f}"
                elif company_value < mean_value:
                    comparison = f"TH·∫§P h∆°n TB {abs(company_value - mean_value):.3f}"
                else:
                    comparison = "B·∫∞NG trung b√¨nh"

                results.append({
                    'feature_code': feature,
                    'feature_name': self.feature_name_mapping[feature],

                    # Gi√° tr·ªã c·ªßa DOANH NGHI·ªÜP N√ÄY
                    'company_value': company_value,
                    'mean_value': mean_value,
                    'z_score': z_score,
                    'comparison': comparison,

                    # Risk contribution C·ª§ TH·ªÇ
                    'risk_contribution': contribution,
                    'risk_contribution_std': contribution_std,
                    'interpretation': interpretation,

                    # Model info (ƒë·ªÉ tham kh·∫£o)
                    'coefficient': coef,
                    'p_value': p_val,
                    'is_significant': p_val < 0.05
                })

        # S·∫Øp x·∫øp theo absolute contribution (ch·ªâ s·ªë ·∫£nh h∆∞·ªüng m·∫°nh nh·∫•t l√™n ƒë·∫ßu)
        results.sort(key=lambda x: abs(x['risk_contribution']), reverse=True)

        # Th√™m th√¥ng tin t·ªïng h·ª£p
        top_results = results[:top_k]

        # T√≠nh % contribution so v·ªõi t·ªïng
        total_abs_contribution = sum(abs(r['risk_contribution']) for r in results)
        for r in top_results:
            if total_abs_contribution > 0:
                r['contribution_pct'] = abs(r['risk_contribution']) / total_abs_contribution * 100
            else:
                r['contribution_pct'] = 0

        return top_results

    def get_survival_probabilities_at_times(self, indicators: Dict[str, float],
                                           times: List[float] = [6, 12, 24],
                                           model_type: str = 'cox') -> Dict[float, float]:
        """
        T√≠nh survival probability t·∫°i c√°c th·ªùi ƒëi·ªÉm c·ª• th·ªÉ

        Args:
            indicators: Dict v·ªõi 14 ch·ªâ s·ªë
            times: List c√°c th·ªùi ƒëi·ªÉm (th√°ng)
            model_type: 'cox' ho·∫∑c 'rsf'

        Returns:
            Dict {time: survival_probability}
        """
        # D·ª± b√°o survival curve
        result = self.predict_survival_curve(indicators, model_type, timeline=None)

        timeline = np.array(result['timeline'])
        survival_probs = np.array(result['survival_probabilities'])

        # Interpolate ƒë·ªÉ l·∫•y survival prob t·∫°i c√°c th·ªùi ƒëi·ªÉm c·ª• th·ªÉ
        probs_at_times = {}
        for t in times:
            if t <= timeline[0]:
                probs_at_times[t] = float(survival_probs[0])
            elif t >= timeline[-1]:
                probs_at_times[t] = float(survival_probs[-1])
            else:
                # Linear interpolation
                idx = np.searchsorted(timeline, t)
                t1, p1 = timeline[idx-1], survival_probs[idx-1]
                t2, p2 = timeline[idx], survival_probs[idx]
                prob = p1 + (t - t1) * (p2 - p1) / (t2 - t1)
                probs_at_times[t] = float(prob)

        return probs_at_times

    def get_risk_classification(self, median_time: float) -> Dict[str, str]:
        """
        Ph√¢n lo·∫°i m·ª©c ƒë·ªô r·ªßi ro d·ª±a tr√™n median time-to-default

        Args:
            median_time: Median time (th√°ng)

        Returns:
            Dict v·ªõi risk level v√† color
        """
        if median_time < 6:
            return {
                'level': 'R·∫•t cao',
                'color': '#FFE8E8',
                'text_color': '#C62828',
                'icon': 'üî¥',
                'description': 'Nguy c∆° v·ª° n·ª£ c·ª±c k·ª≥ cao trong v√≤ng 6 th√°ng'
            }
        elif median_time < 12:
            return {
                'level': 'Cao',
                'color': '#FFE0CC',
                'text_color': '#E65100',
                'icon': 'üü†',
                'description': 'Nguy c∆° v·ª° n·ª£ cao trong v√≤ng 1 nƒÉm'
            }
        elif median_time < 24:
            return {
                'level': 'Trung b√¨nh',
                'color': '#FFF9E8',
                'text_color': '#F57C00',
                'icon': 'üü°',
                'description': 'C·∫ßn theo d√µi ch·∫∑t ch·∫Ω trong v√≤ng 2 nƒÉm'
            }
        elif median_time < 36:
            return {
                'level': 'Th·∫•p',
                'color': '#E8FFF0',
                'text_color': '#1B5E20',
                'icon': 'üü¢',
                'description': 'R·ªßi ro th·∫•p, t√¨nh tr·∫°ng t√†i ch√≠nh ·ªïn ƒë·ªãnh'
            }
        else:
            return {
                'level': 'R·∫•t th·∫•p',
                'color': '#C8F5DC',
                'text_color': '#0D5B2B',
                'icon': 'üü¢',
                'description': 'T√¨nh tr·∫°ng t√†i ch√≠nh r·∫•t t·ªët, r·ªßi ro r·∫•t th·∫•p'
            }

    def save_models(self, filepath: str = 'survival_models.pkl'):
        """L∆∞u models"""
        models = {
            'cox_model': self.cox_model,
            'rsf_model': self.rsf_model,
            'km_fitter': self.km_fitter,
            'training_data': self.training_data,
            'metrics': self.metrics
        }
        joblib.dump(models, filepath)
        return {'status': 'success', 'filepath': filepath}

    def load_models(self, filepath: str = 'survival_models.pkl'):
        """Load models"""
        models = joblib.load(filepath)
        self.cox_model = models['cox_model']
        self.rsf_model = models['rsf_model']
        self.km_fitter = models['km_fitter']
        self.training_data = models['training_data']
        self.metrics = models['metrics']
        return {'status': 'success', 'metrics': self.metrics}


# Singleton instance
survival_system = SurvivalAnalysisSystem()
