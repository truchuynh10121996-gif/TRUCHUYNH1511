"""
Module Anomaly Detection System - H·ªá th·ªëng Ph√°t hi·ªán B·∫•t th∆∞·ªùng
S·ª≠ d·ª•ng Isolation Forest ƒë·ªÉ ph√°t hi·ªán doanh nghi·ªáp c√≥ h√†nh vi b·∫•t th∆∞·ªùng
"""

import pandas as pd
import numpy as np
from typing import Dict, Any, List, Optional
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
import os


class AnomalyDetectionSystem:
    """
    H·ªá th·ªëng Ph√°t hi·ªán B·∫•t th∆∞·ªùng (Anomaly Detection System)

    Ch·ª©c nƒÉng ch√≠nh:
    1. Train Isolation Forest model tr√™n DN kh·ªèe m·∫°nh (label=0)
    2. T√≠nh Anomaly Score (0-100) cho DN m·ªõi
    3. Ph√°t hi·ªán c√°c features b·∫•t th∆∞·ªùng (so v·ªõi P5, P95)
    4. Ph√¢n lo·∫°i lo·∫°i b·∫•t th∆∞·ªùng (Point/Contextual/Collective)
    5. T·∫°o gi·∫£i th√≠ch b·∫±ng Gemini AI
    """

    def __init__(self):
        """Kh·ªüi t·∫°o Anomaly Detection System"""
        self.model = None
        self.scaler = StandardScaler()
        self.thresholds = {}  # P5, P25, P50, P75, P95 cho 14 features
        self.feature_names = []
        self.healthy_stats = {}  # Th·ªëng k√™ DN kh·ªèe m·∫°nh

        # T√™n ƒë·∫ßy ƒë·ªß c·ªßa 14 ch·ªâ s·ªë
        self.indicator_names = {
            'X_1': 'Bi√™n l·ª£i nhu·∫≠n g·ªôp',
            'X_2': 'Bi√™n l·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø',
            'X_3': 'ROA (L·ª£i nhu·∫≠n/T√†i s·∫£n)',
            'X_4': 'ROE (L·ª£i nhu·∫≠n/VCSH)',
            'X_5': 'N·ª£/T√†i s·∫£n',
            'X_6': 'N·ª£/V·ªën ch·ªß s·ªü h·ªØu',
            'X_7': 'Thanh to√°n hi·ªán h√†nh',
            'X_8': 'Thanh to√°n nhanh',
            'X_9': 'Kh·∫£ nƒÉng tr·∫£ l√£i',
            'X_10': 'Kh·∫£ nƒÉng tr·∫£ n·ª£ g·ªëc',
            'X_11': 'T·∫°o ti·ªÅn/VCSH',
            'X_12': 'V√≤ng quay h√†ng t·ªìn kho',
            'X_13': 'K·ª≥ thu ti·ªÅn b√¨nh qu√¢n',
            'X_14': 'Hi·ªáu su·∫•t s·ª≠ d·ª•ng t√†i s·∫£n'
        }

    def train_model(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        Train Isolation Forest model tr√™n DN kh·ªèe m·∫°nh

        Args:
            df: DataFrame ch·ª©a 14 ch·ªâ s·ªë (X_1 ‚Üí X_14) + c·ªôt 'label' (0=kh·ªèe m·∫°nh, 1=v·ª° n·ª£)

        Returns:
            Dict ch·ª©a:
            - feature_statistics: Th·ªëng k√™ 14 features (P5, P25, P50, P75, P95)
            - contamination_rate: T·ª∑ l·ªá contamination
        """
        print("üîÑ B·∫Øt ƒë·∫ßu train Anomaly Detection System...")

        # 1. L·ªåC DN KH·ªéE M·∫†NH (label == 0)
        healthy_df = df[df['label'] == 0].copy()
        print(f"‚úÖ C√≥ {len(healthy_df)} DN kh·ªèe m·∫°nh ƒë·ªÉ train")

        # 2. CHU·∫®N B·ªä FEATURES
        self.feature_names = [f'X_{i}' for i in range(1, 15)]
        X_healthy = healthy_df[self.feature_names].values

        # 3. CHU·∫®N H√ìA D·ªÆ LI·ªÜU (FIT TR√äN DN KH·ªéE M·∫†NH)
        X_scaled = self.scaler.fit_transform(X_healthy)

        # 4. T√çNH THRESHOLDS (P5, P25, P50, P75, P95) CHO 14 FEATURES
        percentiles = [5, 25, 50, 75, 95]
        for i, feature in enumerate(self.feature_names):
            self.thresholds[feature] = {
                f'P{p}': np.percentile(X_healthy[:, i], p) for p in percentiles
            }

        # 5. T√çNH TH·ªêNG K√ä DN KH·ªéE M·∫†NH (ƒë·ªÉ so s√°nh)
        for i, feature in enumerate(self.feature_names):
            self.healthy_stats[feature] = {
                'mean': np.mean(X_healthy[:, i]),
                'std': np.std(X_healthy[:, i]),
                'min': np.min(X_healthy[:, i]),
                'max': np.max(X_healthy[:, i])
            }

        # 6. TRAIN ISOLATION FOREST
        print("üìä Training Isolation Forest...")
        self.model = IsolationForest(
            n_estimators=100,
            contamination=0.05,  # 5% DN b·∫•t th∆∞·ªùng
            random_state=42,
            n_jobs=-1
        )
        self.model.fit(X_scaled)
        print("‚úÖ Train Isolation Forest ho√†n t·∫•t!")

        # 7. CHU·∫®N B·ªä K·∫æT QU·∫¢ TR·∫¢ V·ªÄ
        feature_statistics = []
        for feature in self.feature_names:
            feature_statistics.append({
                'feature': feature,
                'name': self.indicator_names[feature],
                'P5': round(self.thresholds[feature]['P5'], 4),
                'P25': round(self.thresholds[feature]['P25'], 4),
                'P50': round(self.thresholds[feature]['P50'], 4),
                'P75': round(self.thresholds[feature]['P75'], 4),
                'P95': round(self.thresholds[feature]['P95'], 4),
                'mean': round(self.healthy_stats[feature]['mean'], 4)
            })

        return {
            'feature_statistics': feature_statistics,
            'contamination_rate': 0.05,
            'num_healthy_samples': len(healthy_df),
            'num_total_samples': len(df)
        }

    def calculate_anomaly_score(self, indicators: Dict[str, float]) -> float:
        """
        T√≠nh Anomaly Score (0-100) cho DN m·ªõi

        Args:
            indicators: Dict ch·ª©a 14 ch·ªâ s·ªë (X_1 ‚Üí X_14)

        Returns:
            anomaly_score: ƒêi·ªÉm b·∫•t th∆∞·ªùng (0-100), c√†ng cao c√†ng b·∫•t th∆∞·ªùng
        """
        if self.model is None:
            raise ValueError("Model ch∆∞a ƒë∆∞·ª£c train. Vui l√≤ng train model tr∆∞·ªõc.")

        # Chu·∫©n b·ªã input
        X_new = [[indicators[f] for f in self.feature_names]]
        X_scaled = self.scaler.transform(X_new)

        # T√≠nh decision_function (raw score)
        # decision_function: c√†ng √¢m c√†ng b·∫•t th∆∞·ªùng, c√†ng d∆∞∆°ng c√†ng b√¨nh th∆∞·ªùng
        raw_score = self.model.decision_function(X_scaled)[0]

        # Normalize v·ªÅ [0, 100]
        # D·ª±a tr√™n kinh nghi·ªám: decision_function th∆∞·ªùng trong kho·∫£ng [-0.5, 0.5]
        # -0.5 ‚Üí 100 (r·∫•t b·∫•t th∆∞·ªùng)
        # 0.5 ‚Üí 0 (r·∫•t b√¨nh th∆∞·ªùng)
        anomaly_score = max(0, min(100, (0.5 - raw_score) * 100))

        return round(anomaly_score, 2)

    def detect_abnormal_features(self, indicators: Dict[str, float]) -> List[Dict[str, Any]]:
        """
        Ph√°t hi·ªán c√°c features b·∫•t th∆∞·ªùng (so v·ªõi P5, P95)

        Args:
            indicators: Dict ch·ª©a 14 ch·ªâ s·ªë (X_1 ‚Üí X_14)

        Returns:
            List of Dict ch·ª©a th√¥ng tin c√°c features b·∫•t th∆∞·ªùng:
            [{
                'feature_name': str,
                'current_value': float,
                'p5': float,
                'p50': float,
                'p95': float,
                'deviation_percent': float,
                'severity': str  # 'high' ho·∫∑c 'medium'
            }]
        """
        abnormal_features = []

        for feature in self.feature_names:
            current_value = indicators[feature]
            p5 = self.thresholds[feature]['P5']
            p50 = self.thresholds[feature]['P50']
            p95 = self.thresholds[feature]['P95']

            # Ki·ªÉm tra b·∫•t th∆∞·ªùng
            is_abnormal = False
            deviation_percent = 0
            severity = 'medium'

            if current_value < p5:
                # Th·∫•p h∆°n P5 ‚Üí B·∫•t th∆∞·ªùng
                is_abnormal = True
                deviation_percent = ((p5 - current_value) / abs(p5) * 100) if p5 != 0 else 0
                severity = 'high' if deviation_percent > 50 else 'medium'
            elif current_value > p95:
                # Cao h∆°n P95 ‚Üí B·∫•t th∆∞·ªùng
                is_abnormal = True
                deviation_percent = ((current_value - p95) / abs(p95) * 100) if p95 != 0 else 0

                # ƒê·∫∂C BI·ªÜT: ƒê·ªëi v·ªõi m·ªôt s·ªë ch·ªâ s·ªë, cao h∆°n P95 l√† T·ªêT (kh√¥ng ph·∫£i b·∫•t th∆∞·ªùng)
                good_if_high = ['X_1', 'X_2', 'X_3', 'X_4', 'X_7', 'X_8', 'X_9', 'X_10', 'X_11', 'X_12', 'X_14']
                if feature in good_if_high:
                    # Ch·ªâ s·ªë n√†y cao l√† t·ªët ‚Üí Kh√¥ng coi l√† b·∫•t th∆∞·ªùng
                    is_abnormal = False
                else:
                    # Ch·ªâ s·ªë n√†y cao l√† x·∫•u (X_5, X_6, X_13)
                    severity = 'high' if deviation_percent > 50 else 'medium'

            if is_abnormal:
                abnormal_features.append({
                    'feature_code': feature,
                    'feature_name': self.indicator_names[feature],
                    'current_value': round(current_value, 4),
                    'p5': round(p5, 4),
                    'p50': round(p50, 4),
                    'p95': round(p95, 4),
                    'deviation_percent': round(abs(deviation_percent), 2),
                    'severity': severity,
                    'direction': 'low' if current_value < p5 else 'high'
                })

        # S·∫Øp x·∫øp theo ƒë·ªô l·ªách gi·∫£m d·∫ßn
        abnormal_features.sort(key=lambda x: x['deviation_percent'], reverse=True)

        return abnormal_features

    def classify_anomaly_type(self, indicators: Dict[str, float], abnormal_features: List[Dict]) -> str:
        """
        Ph√¢n lo·∫°i lo·∫°i b·∫•t th∆∞·ªùng

        Args:
            indicators: Dict ch·ª©a 14 ch·ªâ s·ªë
            abnormal_features: List c√°c features b·∫•t th∆∞·ªùng

        Returns:
            anomaly_type: "Point Anomaly", "Contextual Anomaly", ho·∫∑c "Collective Anomaly"
        """
        num_abnormal = len(abnormal_features)

        if num_abnormal == 0:
            return "Normal"
        elif num_abnormal == 1:
            return "Point Anomaly"
        elif num_abnormal >= 5:
            return "Collective Anomaly"
        else:
            return "Contextual Anomaly"

    def generate_gemini_explanation(
        self,
        indicators: Dict[str, float],
        anomaly_score: float,
        abnormal_features: List[Dict],
        anomaly_type: str,
        gemini_api_key: str
    ) -> str:
        """
        T·∫°o gi·∫£i th√≠ch vƒÉn xu√¥i b·∫±ng Gemini AI

        Args:
            indicators: Dict ch·ª©a 14 ch·ªâ s·ªë
            anomaly_score: ƒêi·ªÉm b·∫•t th∆∞·ªùng (0-100)
            abnormal_features: List c√°c features b·∫•t th∆∞·ªùng
            anomaly_type: Lo·∫°i b·∫•t th∆∞·ªùng
            gemini_api_key: Gemini API key

        Returns:
            explanation: Gi·∫£i th√≠ch vƒÉn xu√¥i (ti·∫øng Vi·ªát, 200-300 t·ª´)
        """
        try:
            import google.generativeai as genai

            # C·∫•u h√¨nh Gemini API
            genai.configure(api_key=gemini_api_key)
            model = genai.GenerativeModel('gemini-2.0-flash')

            # T·∫°o prompt chi ti·∫øt
            prompt = f"""
B·∫°n l√† chuy√™n gia ph√°t hi·ªán gian l·∫≠n t√†i ch√≠nh c·ªßa Agribank. H√£y ph√¢n t√≠ch k·∫øt qu·∫£ ph√°t hi·ªán b·∫•t th∆∞·ªùng d∆∞·ªõi ƒë√¢y.

**TH√îNG TIN DOANH NGHI·ªÜP:**

**Anomaly Score:** {anomaly_score}/100 (ƒêi·ªÉm b·∫•t th∆∞·ªùng)
**Lo·∫°i b·∫•t th∆∞·ªùng:** {anomaly_type}

**14 CH·ªà S·ªê T√ÄI CH√çNH:**
"""

            # Th√™m 14 ch·ªâ s·ªë
            for feature in self.feature_names:
                prompt += f"- {self.indicator_names[feature]} ({feature}): {indicators[feature]:.4f}\n"

            prompt += f"\n**C√ÅC CH·ªà S·ªê B·∫§T TH∆Ø·ªúNG ({len(abnormal_features)} ch·ªâ s·ªë):**\n"

            if len(abnormal_features) > 0:
                for ab in abnormal_features[:5]:  # Top 5
                    prompt += f"""
- {ab['feature_name']} ({ab['feature_code']}):
  + Gi√° tr·ªã hi·ªán t·∫°i: {ab['current_value']:.4f}
  + Ng∆∞·ª°ng b√¨nh th∆∞·ªùng: P5={ab['p5']:.4f}, P50={ab['p50']:.4f}, P95={ab['p95']:.4f}
  + ƒê·ªô l·ªách: {ab['deviation_percent']:.2f}% ({ab['direction']})
  + M·ª©c ƒë·ªô nghi√™m tr·ªçng: {ab['severity']}
"""
            else:
                prompt += "- Kh√¥ng c√≥ ch·ªâ s·ªë b·∫•t th∆∞·ªùng\n"

            prompt += """

**Y√äU C·∫¶U PH√ÇN T√çCH:**

H√£y vi·∫øt b√°o c√°o ph√¢n t√≠ch chi ti·∫øt (200-300 t·ª´, ti·∫øng Vi·ªát) v·ªõi c·∫•u tr√∫c sau:

## üîç ƒê√ÅNH GI√Å T·ªîNG QUAN
(2-3 c√¢u m√¥ t·∫£ m·ª©c ƒë·ªô b·∫•t th∆∞·ªùng c·ªßa doanh nghi·ªáp)

## üìä PH√ÇN T√çCH C√ÅC CH·ªà S·ªê B·∫§T TH∆Ø·ªúNG
(Ph√¢n t√≠ch chi ti·∫øt t·ª´ng ch·ªâ s·ªë b·∫•t th∆∞·ªùng, gi·∫£i th√≠ch t·∫°i sao b·∫•t th∆∞·ªùng)

## ‚ö†Ô∏è R·ª¶I RO TI·ªÄM ·∫®N
(Li·ªát k√™ 2-3 r·ªßi ro c√≥ th·ªÉ x·∫£y ra: gian l·∫≠n, b√°o c√°o sai, ho·∫°t ƒë·ªông b·∫•t th∆∞·ªùng, v.v.)

## üí° KHUY·∫æN NGH·ªä
(ƒê∆∞a ra 2-3 khuy·∫øn ngh·ªã c·ª• th·ªÉ cho ng√¢n h√†ng: c·∫ßn xem x√©t, ki·ªÉm tra s√¢u, y√™u c·∫ßu gi·∫£i tr√¨nh, v.v.)

---
**L∆∞u √Ω:** Vi·∫øt ng·∫Øn g·ªçn, chuy√™n nghi·ªáp, d·ªÖ hi·ªÉu. T·∫≠p trung v√†o ph√°t hi·ªán d·∫•u hi·ªáu b·∫•t th∆∞·ªùng v√† ƒë∆∞a ra c·∫£nh b√°o c·ª• th·ªÉ.
"""

            # G·ªçi Gemini API
            response = model.generate_content(prompt)
            explanation = response.text

            return explanation

        except Exception as e:
            return f"L·ªói khi g·ªçi Gemini API: {str(e)}"


# Kh·ªüi t·∫°o singleton instance
anomaly_system = AnomalyDetectionSystem()
