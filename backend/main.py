"""
FastAPI Backend - Há»‡ thá»‘ng ÄÃ¡nh giÃ¡ Rá»§i ro TÃ­n dá»¥ng
Endpoints: /train, /predict, /predict-from-xlsx, /analyze, /export-report
"""

from fastapi import FastAPI, UploadFile, File, HTTPException, Form
from dotenv import load_dotenv
import os

load_dotenv()  # Táº£i cÃ¡c biáº¿n mÃ´i trÆ°á»ng tá»« file .env

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse
from pydantic import BaseModel
from typing import Dict, Any, Optional, List
import pandas as pd
import os
import tempfile
from datetime import datetime
from model import credit_model
from gemini_api import get_gemini_analyzer
from excel_processor import excel_processor
from report_generator import ReportGenerator
from early_warning import early_warning_system
from anomaly_detection import anomaly_system
from survival_analysis import survival_system

# Khá»Ÿi táº¡o FastAPI app
app = FastAPI(
    title="Credit Risk Assessment API",
    description="API Ä‘Ã¡nh giÃ¡ rá»§i ro tÃ­n dá»¥ng sá»­ dá»¥ng Stacking Classifier",
    version="1.0.0"
)

# Cáº¥u hÃ¬nh CORS Ä‘á»ƒ frontend Vue cÃ³ thá»ƒ gá»i API
# Development: cho phÃ©p localhost:3000 (frontend Vue)
# Production: thay Ä‘á»•i origins theo domain tháº­t
origins = [
    "http://localhost:3000",      # Vue dev server
    "http://localhost:5173",      # Vite alternative port
    "http://127.0.0.1:3000",
    "http://127.0.0.1:5173",
    # ThÃªm domain production khi deploy:
    # "https://yourdomain.com"
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
    expose_headers=["*"],
)


# ================================================================================================
# HELPER FUNCTIONS
# ================================================================================================

def convert_to_json_serializable(obj):
    """
    Chuyá»ƒn Ä‘á»•i numpy/pandas types sang Python native types Ä‘á»ƒ JSON serialization
    Xá»­ lÃ½ cÃ¡c giÃ¡ trá»‹ float Ä‘áº·c biá»‡t (inf, -inf, nan) khÃ´ng há»£p lá»‡ trong JSON
    """
    import numpy as np
    import math

    if isinstance(obj, dict):
        return {key: convert_to_json_serializable(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_to_json_serializable(item) for item in obj]
    elif isinstance(obj, (np.integer, np.int64, np.int32, np.int16, np.int8)):
        return int(obj)
    elif isinstance(obj, (np.floating, np.float64, np.float32, np.float16)):
        # Convert numpy float to Python float
        val = float(obj)
        # Kiá»ƒm tra vÃ  xá»­ lÃ½ cÃ¡c giÃ¡ trá»‹ Ä‘áº·c biá»‡t khÃ´ng há»£p lá»‡ trong JSON
        if math.isnan(val) or math.isinf(val):
            return None  # Hoáº·c cÃ³ thá»ƒ return 0, tÃ¹y vÃ o yÃªu cáº§u
        return val
    elif isinstance(obj, float):
        # Xá»­ lÃ½ Python float (khÃ´ng pháº£i numpy)
        if math.isnan(obj) or math.isinf(obj):
            return None
        return obj
    elif isinstance(obj, np.ndarray):
        return convert_to_json_serializable(obj.tolist())
    elif isinstance(obj, (np.bool_, bool)):
        return bool(obj)
    elif pd.isna(obj):
        return None
    else:
        return obj


def downsample_kaplan_meier(km_data: Dict[str, Any], max_points: int = 100) -> Dict[str, Any]:
    """
    Downsample Kaplan-Meier data Ä‘á»ƒ giáº£m kÃ­ch thÆ°á»›c response
    Giá»¯ láº¡i max_points Ä‘iá»ƒm quan trá»ng nháº¥t

    Args:
        km_data: Dict chá»©a timeline vÃ  survival_probabilities
        max_points: Sá»‘ Ä‘iá»ƒm tá»‘i Ä‘a muá»‘n giá»¯ láº¡i

    Returns:
        Dict vá»›i downsampled data
    """
    if not km_data or 'timeline' not in km_data or 'survival_probabilities' not in km_data:
        return km_data

    timeline = km_data['timeline']
    survival_probs = km_data['survival_probabilities']

    # Náº¿u sá»‘ Ä‘iá»ƒm Ã­t hÆ¡n max_points, khÃ´ng cáº§n downsample
    if len(timeline) <= max_points:
        return km_data

    # Downsample: láº¥y má»—i n Ä‘iá»ƒm
    step = len(timeline) // max_points
    if step < 1:
        step = 1

    # LuÃ´n giá»¯ Ä‘iá»ƒm Ä‘áº§u vÃ  Ä‘iá»ƒm cuá»‘i
    indices = list(range(0, len(timeline), step))
    if len(timeline) - 1 not in indices:
        indices.append(len(timeline) - 1)

    downsampled_timeline = [timeline[i] for i in indices]
    downsampled_probs = [survival_probs[i] for i in indices]

    print(f"ğŸ”½ [DOWNSAMPLE] Kaplan-Meier: {len(timeline)} Ä‘iá»ƒm â†’ {len(downsampled_timeline)} Ä‘iá»ƒm")

    return {
        'timeline': downsampled_timeline,
        'survival_probabilities': downsampled_probs,
        'median_survival_time': km_data.get('median_survival_time'),
        'event_count': km_data.get('event_count'),
        'censored_count': km_data.get('censored_count'),
        'original_points': len(timeline),  # ThÃ´ng tin vá» sá»‘ Ä‘iá»ƒm gá»‘c
        'downsampled': True
    }


# ================================================================================================
# PYDANTIC MODELS
# ================================================================================================

class PredictionInput(BaseModel):
    """Model cho input dá»± bÃ¡o (14 chá»‰ sá»‘ X1-X14)"""
    X_1: float
    X_2: float
    X_3: float
    X_4: float
    X_5: float
    X_6: float
    X_7: float
    X_8: float
    X_9: float
    X_10: float
    X_11: float
    X_12: float
    X_13: float
    X_14: float


class GeminiAPIKeyRequest(BaseModel):
    """Model cho request set Gemini API key"""
    api_key: str


# ================================================================================================
# ENDPOINTS
# ================================================================================================

@app.get("/")
async def root():
    """Health check endpoint"""
    return {
        "message": "Credit Risk Assessment API",
        "version": "1.0.0",
        "status": "running"
    }


@app.post("/train")
async def train_model(file: UploadFile = File(...)):
    """
    Endpoint huáº¥n luyá»‡n mÃ´ hÃ¬nh tá»« file CSV

    Args:
        file: File CSV chá»©a dá»¯ liá»‡u huáº¥n luyá»‡n (pháº£i cÃ³ cá»™t X_1 Ä‘áº¿n X_14 vÃ  cá»™t 'default')

    Returns:
        Dict chá»©a thÃ´ng tin huáº¥n luyá»‡n vÃ  metrics
    """
    try:
        # Kiá»ƒm tra file extension
        if not file.filename.endswith('.csv'):
            raise HTTPException(status_code=400, detail="File pháº£i cÃ³ Ä‘á»‹nh dáº¡ng CSV")

        # LÆ°u file táº¡m
        with tempfile.NamedTemporaryFile(delete=False, suffix='.csv') as tmp_file:
            content = await file.read()
            tmp_file.write(content)
            tmp_file_path = tmp_file.name

        # Huáº¥n luyá»‡n mÃ´ hÃ¬nh
        result = credit_model.train(tmp_file_path)

        # LÆ°u mÃ´ hÃ¬nh
        credit_model.save_model("model_stacking.pkl")

        # XÃ³a file táº¡m
        os.unlink(tmp_file_path)

        return convert_to_json_serializable(result)

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi huáº¥n luyá»‡n mÃ´ hÃ¬nh: {str(e)}")


@app.post("/predict")
async def predict(input_data: PredictionInput):
    """
    Endpoint dá»± bÃ¡o PD tá»« 14 chá»‰ sá»‘ tÃ i chÃ­nh

    Args:
        input_data: Dict chá»©a 14 chá»‰ sá»‘ X_1 Ä‘áº¿n X_14

    Returns:
        Dict chá»©a PD tá»« 4 models vÃ  káº¿t quáº£ dá»± Ä‘oÃ¡n
    """
    try:
        # Kiá»ƒm tra mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c train chÆ°a
        if credit_model.model is None:
            # Thá»­ load model tá»« file
            if os.path.exists("model_stacking.pkl"):
                credit_model.load_model("model_stacking.pkl")
            else:
                raise HTTPException(
                    status_code=400,
                    detail="MÃ´ hÃ¬nh chÆ°a Ä‘Æ°á»£c huáº¥n luyá»‡n. Vui lÃ²ng upload file CSV Ä‘á»ƒ huáº¥n luyá»‡n trÆ°á»›c."
                )

        # Chuyá»ƒn input thÃ nh DataFrame
        input_dict = input_data.dict()
        X_new = pd.DataFrame([input_dict])

        # Dá»± bÃ¡o
        result = credit_model.predict(X_new)

        return convert_to_json_serializable(result)

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi dá»± bÃ¡o: {str(e)}")


@app.post("/predict-from-xlsx")
async def predict_from_xlsx(file: UploadFile = File(...)):
    """
    Endpoint dá»± bÃ¡o PD tá»« file XLSX (3 sheets: CDKT, BCTN, LCTT)
    Tá»± Ä‘á»™ng tÃ­nh 14 chá»‰ sá»‘ vÃ  cháº¡y mÃ´ hÃ¬nh dá»± bÃ¡o

    Args:
        file: File XLSX chá»©a 3 sheets (CDKT, BCTN, LCTT)

    Returns:
        Dict chá»©a 14 chá»‰ sá»‘ vÃ  káº¿t quáº£ dá»± bÃ¡o PD
    """
    try:
        # Kiá»ƒm tra file extension
        if not file.filename.endswith(('.xlsx', '.xls')):
            raise HTTPException(status_code=400, detail="File pháº£i cÃ³ Ä‘á»‹nh dáº¡ng XLSX hoáº·c XLS")

        # Kiá»ƒm tra mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c train chÆ°a
        if credit_model.model is None:
            if os.path.exists("model_stacking.pkl"):
                credit_model.load_model("model_stacking.pkl")
            else:
                raise HTTPException(
                    status_code=400,
                    detail="MÃ´ hÃ¬nh chÆ°a Ä‘Æ°á»£c huáº¥n luyá»‡n. Vui lÃ²ng upload file CSV Ä‘á»ƒ huáº¥n luyá»‡n trÆ°á»›c."
                )

        # LÆ°u file táº¡m
        with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp_file:
            content = await file.read()
            tmp_file.write(content)
            tmp_file_path = tmp_file.name

        try:
            # Äá»c file XLSX
            excel_processor.read_excel(tmp_file_path)

            # TÃ­nh 14 chá»‰ sá»‘
            indicators = excel_processor.calculate_14_indicators()
            indicators_with_names = excel_processor.get_indicators_with_names()

            # Chuyá»ƒn thÃ nh DataFrame Ä‘á»ƒ dá»± bÃ¡o
            X_new = pd.DataFrame([indicators])

            # Dá»± bÃ¡o PD
            prediction_result = credit_model.predict(X_new)

            # Tráº£ vá» káº¿t quáº£
            response_data = {
                "status": "success",
                "indicators": indicators_with_names,
                "indicators_dict": indicators,
                "prediction": prediction_result
            }

            return convert_to_json_serializable(response_data)
        finally:
            # XÃ³a file táº¡m trong finally block Ä‘á»ƒ Ä‘áº£m báº£o file luÃ´n Ä‘Æ°á»£c xÃ³a
            try:
                os.unlink(tmp_file_path)
            except Exception:
                pass  # Bá» qua lá»—i khi xÃ³a file

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi xá»­ lÃ½ file XLSX: {str(e)}")


@app.post("/analyze")
async def analyze_with_gemini(request_data: Dict[str, Any]):
    """
    Endpoint phÃ¢n tÃ­ch káº¿t quáº£ dá»± bÃ¡o báº±ng Gemini API

    Args:
        request_data: Dict chá»©a káº¿t quáº£ dá»± bÃ¡o vÃ  14 chá»‰ sá»‘

    Returns:
        Dict chá»©a káº¿t quáº£ phÃ¢n tÃ­ch tá»« Gemini vÃ  khuyáº¿n nghá»‹
    """
    try:
        # Láº¥y Gemini analyzer
        analyzer = get_gemini_analyzer()

        # PhÃ¢n tÃ­ch
        analysis = analyzer.analyze_credit_risk(request_data)

        return {
            "status": "success",
            "analysis": analysis
        }

    except ValueError as e:
        raise HTTPException(
            status_code=400,
            detail=f"KhÃ´ng tÃ¬m tháº¥y GEMINI_API_KEY. Vui lÃ²ng set biáº¿n mÃ´i trÆ°á»ng. Chi tiáº¿t: {str(e)}"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi phÃ¢n tÃ­ch báº±ng Gemini: {str(e)}")


@app.post("/analyze-industry")
async def analyze_industry(request_data: Dict[str, Any]):
    """
    Endpoint phÃ¢n tÃ­ch ngÃ nh nghá» báº±ng Gemini API

    Args:
        request_data: Dict chá»©a industry code vÃ  industry_name

    Returns:
        Dict chá»©a káº¿t quáº£ phÃ¢n tÃ­ch ngÃ nh vÃ  dá»¯ liá»‡u charts
    """
    try:
        industry = request_data.get('industry', '')
        industry_name = request_data.get('industry_name', '')

        if not industry or not industry_name:
            raise HTTPException(
                status_code=400,
                detail="Thiáº¿u thÃ´ng tin industry hoáº·c industry_name"
            )

        # Láº¥y Gemini analyzer
        analyzer = get_gemini_analyzer()

        # PhÃ¢n tÃ­ch ngÃ nh
        result = analyzer.analyze_industry(industry, industry_name)

        return {
            "status": "success",
            "analysis": result["analysis"],
            "charts": result.get("charts", [])
        }

    except ValueError as e:
        raise HTTPException(
            status_code=400,
            detail=f"KhÃ´ng tÃ¬m tháº¥y GEMINI_API_KEY. Vui lÃ²ng set biáº¿n mÃ´i trÆ°á»ng. Chi tiáº¿t: {str(e)}"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi phÃ¢n tÃ­ch ngÃ nh: {str(e)}")


@app.post("/set-gemini-key")
async def set_gemini_key(request: GeminiAPIKeyRequest):
    """
    Endpoint Ä‘á»ƒ set Gemini API key

    Args:
        request: Dict chá»©a api_key

    Returns:
        Dict xÃ¡c nháº­n
    """
    try:
        os.environ["GEMINI_API_KEY"] = request.api_key

        # Khá»Ÿi táº¡o láº¡i Gemini analyzer - cáº­p nháº­t global instance
        from gemini_api import GeminiAnalyzer
        import gemini_api
        gemini_api.gemini_analyzer = GeminiAnalyzer(request.api_key)

        return {
            "status": "success",
            "message": "Gemini API key Ä‘Ã£ Ä‘Æ°á»£c set thÃ nh cÃ´ng"
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi set Gemini API key: {str(e)}")


@app.post("/export-report")
async def export_report(report_data: Dict[str, Any]):
    """
    Endpoint xuáº¥t bÃ¡o cÃ¡o Word

    Args:
        report_data: Dict chá»©a prediction, indicators, vÃ  analysis

    Returns:
        File Word bÃ¡o cÃ¡o
    """
    try:
        # Táº¡o bÃ¡o cÃ¡o
        report_gen = ReportGenerator()
        output_path = f"bao_cao_tin_dung_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx"

        report_path = report_gen.generate_report(report_data, output_path)

        # Tráº£ vá» file
        return FileResponse(
            path=report_path,
            media_type='application/vnd.openxmlformats-officedocument.wordprocessingml.document',
            filename=output_path
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi xuáº¥t bÃ¡o cÃ¡o: {str(e)}")


@app.post("/fetch-industry-data")
async def fetch_industry_data(request_data: Dict[str, Any]):
    """
    Endpoint Ä‘á»ƒ AI láº¥y dá»¯ liá»‡u ngÃ nh nghá» tá»± Ä‘á»™ng

    Args:
        request_data: Dict chá»©a industry code vÃ  industry_name

    Returns:
        Dict chá»©a dá»¯ liá»‡u ngÃ nh nghá»
    """
    try:
        industry = request_data.get('industry', '')
        industry_name = request_data.get('industry_name', '')

        if not industry or not industry_name:
            raise HTTPException(
                status_code=400,
                detail="Thiáº¿u thÃ´ng tin industry hoáº·c industry_name"
            )

        # Láº¥y Gemini analyzer
        analyzer = get_gemini_analyzer()

        # Láº¥y dá»¯ liá»‡u
        result = analyzer.fetch_industry_data(industry, industry_name)

        return {
            "status": "success",
            "data": result.get("data", {})
        }

    except ValueError as e:
        raise HTTPException(
            status_code=400,
            detail=f"KhÃ´ng tÃ¬m tháº¥y GEMINI_API_KEY. Vui lÃ²ng set biáº¿n mÃ´i trÆ°á»ng. Chi tiáº¿t: {str(e)}"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi láº¥y dá»¯ liá»‡u ngÃ nh: {str(e)}")


@app.post("/generate-charts")
async def generate_charts(request_data: Dict[str, Any]):
    """
    Endpoint táº¡o biá»ƒu Ä‘á»“ ECharts vÃ  phÃ¢n tÃ­ch sÆ¡ bá»™

    Args:
        request_data: Dict chá»©a industry, industry_name, vÃ  data

    Returns:
        Dict chá»©a charts_data vÃ  brief_analysis
    """
    try:
        industry = request_data.get('industry', '')
        industry_name = request_data.get('industry_name', '')
        data = request_data.get('data', {})

        if not industry or not industry_name or not data:
            raise HTTPException(
                status_code=400,
                detail="Thiáº¿u thÃ´ng tin industry, industry_name hoáº·c data"
            )

        # Láº¥y Gemini analyzer
        analyzer = get_gemini_analyzer()

        # Táº¡o biá»ƒu Ä‘á»“ vÃ  phÃ¢n tÃ­ch
        result = analyzer.generate_charts_data(industry, industry_name, data)

        return {
            "status": "success",
            "charts_data": result.get("charts_data", []),
            "brief_analysis": result.get("brief_analysis", "")
        }

    except ValueError as e:
        raise HTTPException(
            status_code=400,
            detail=f"KhÃ´ng tÃ¬m tháº¥y GEMINI_API_KEY. Vui lÃ²ng set biáº¿n mÃ´i trÆ°á»ng. Chi tiáº¿t: {str(e)}"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi táº¡o biá»ƒu Ä‘á»“: {str(e)}")


@app.post("/deep-analyze-industry")
async def deep_analyze_industry_endpoint(request_data: Dict[str, Any]):
    """
    Endpoint phÃ¢n tÃ­ch sÃ¢u áº£nh hÆ°á»Ÿng cá»§a ngÃ nh Ä‘áº¿n quyáº¿t Ä‘á»‹nh cho vay

    Args:
        request_data: Dict chá»©a industry, industry_name, data, vÃ  brief_analysis

    Returns:
        Dict chá»©a deep_analysis
    """
    try:
        industry = request_data.get('industry', '')
        industry_name = request_data.get('industry_name', '')
        data = request_data.get('data', {})
        brief_analysis = request_data.get('brief_analysis', '')

        if not industry or not industry_name or not data:
            raise HTTPException(
                status_code=400,
                detail="Thiáº¿u thÃ´ng tin industry, industry_name hoáº·c data"
            )

        # Láº¥y Gemini analyzer
        analyzer = get_gemini_analyzer()

        # PhÃ¢n tÃ­ch sÃ¢u
        deep_analysis = analyzer.deep_analyze_industry(industry, industry_name, data, brief_analysis)

        return {
            "status": "success",
            "deep_analysis": deep_analysis
        }

    except ValueError as e:
        raise HTTPException(
            status_code=400,
            detail=f"KhÃ´ng tÃ¬m tháº¥y GEMINI_API_KEY. Vui lÃ²ng set biáº¿n mÃ´i trÆ°á»ng. Chi tiáº¿t: {str(e)}"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi phÃ¢n tÃ­ch sÃ¢u: {str(e)}")


@app.post("/analyze-pd-with-industry")
async def analyze_pd_with_industry(request_data: Dict[str, Any]):
    """
    Endpoint phÃ¢n tÃ­ch PD káº¿t há»£p vá»›i ngÃ nh nghá»

    Args:
        request_data: Dict chá»©a indicators_dict, industry, vÃ  industry_name

    Returns:
        Dict chá»©a phÃ¢n tÃ­ch chuyÃªn sÃ¢u vÃ  charts_data
    """
    try:
        indicators_dict = request_data.get('indicators_dict', {})
        industry = request_data.get('industry', '')
        industry_name = request_data.get('industry_name', '')

        if not indicators_dict or not industry or not industry_name:
            raise HTTPException(
                status_code=400,
                detail="Thiáº¿u thÃ´ng tin indicators_dict, industry hoáº·c industry_name"
            )

        # Láº¥y Gemini analyzer
        analyzer = get_gemini_analyzer()

        # PhÃ¢n tÃ­ch PD káº¿t há»£p
        analysis = analyzer.analyze_pd_with_industry(indicators_dict, industry, industry_name)

        # Táº¡o biá»ƒu Ä‘á»“ tá»« 14 chá»‰ sá»‘
        charts_data = []

        # Biá»ƒu Ä‘á»“ 1: Radar chart cho 4 nhÃ³m chá»‰ sá»‘ chÃ­nh
        charts_data.append({
            "title": {"text": "Tá»•ng quan 14 Chá»‰ sá»‘ TÃ i chÃ­nh", "left": "center"},
            "tooltip": {},
            "radar": {
                "indicator": [
                    {"name": "Sinh lá»i (X1-X4)", "max": 1},
                    {"name": "ÄÃ²n báº©y (X5-X6)", "max": 5},
                    {"name": "Thanh toÃ¡n (X7-X8)", "max": 5},
                    {"name": "Hiá»‡u quáº£ (X9-X14)", "max": 10}
                ]
            },
            "series": [{
                "type": "radar",
                "data": [{
                    "value": [
                        (indicators_dict.get('X_1', 0) + indicators_dict.get('X_2', 0) +
                         indicators_dict.get('X_3', 0) + indicators_dict.get('X_4', 0)) / 4,
                        (indicators_dict.get('X_5', 0) + indicators_dict.get('X_6', 0)) / 2,
                        (indicators_dict.get('X_7', 0) + indicators_dict.get('X_8', 0)) / 2,
                        (indicators_dict.get('X_9', 0) + indicators_dict.get('X_10', 0) +
                         indicators_dict.get('X_11', 0) + indicators_dict.get('X_12', 0) +
                         indicators_dict.get('X_14', 0)) / 5
                    ],
                    "name": "Chá»‰ sá»‘ doanh nghiá»‡p",
                    "areaStyle": {"color": "rgba(255, 107, 157, 0.3)"}
                }]
            }]
        })

        # Biá»ƒu Ä‘á»“ 2: Bar chart so sÃ¡nh chá»‰ sá»‘ sinh lá»i
        charts_data.append({
            "title": {"text": "Chá»‰ sá»‘ Sinh lá»i (X1-X4)", "left": "center"},
            "tooltip": {"trigger": "axis"},
            "xAxis": {
                "type": "category",
                "data": ["BiÃªn LN gá»™p (X1)", "BiÃªn LN trÆ°á»›c thuáº¿ (X2)", "ROA (X3)", "ROE (X4)"]
            },
            "yAxis": {"type": "value"},
            "series": [{
                "data": [
                    indicators_dict.get('X_1', 0),
                    indicators_dict.get('X_2', 0),
                    indicators_dict.get('X_3', 0),
                    indicators_dict.get('X_4', 0)
                ],
                "type": "bar",
                "itemStyle": {"color": "#10B981"},
                "label": {"show": True, "position": "top", "formatter": "{c}"}
            }]
        })

        # Biá»ƒu Ä‘á»“ 3: Bar chart chá»‰ sá»‘ thanh toÃ¡n & Ä‘Ã²n báº©y
        charts_data.append({
            "title": {"text": "Thanh toÃ¡n & ÄÃ²n báº©y (X5-X8)", "left": "center"},
            "tooltip": {"trigger": "axis"},
            "xAxis": {
                "type": "category",
                "data": ["Ná»£/TS (X5)", "Ná»£/VCSH (X6)", "TT hiá»‡n hÃ nh (X7)", "TT nhanh (X8)"]
            },
            "yAxis": {"type": "value"},
            "series": [{
                "data": [
                    indicators_dict.get('X_5', 0),
                    indicators_dict.get('X_6', 0),
                    indicators_dict.get('X_7', 0),
                    indicators_dict.get('X_8', 0)
                ],
                "type": "bar",
                "itemStyle": {"color": "#3B82F6"},
                "label": {"show": True, "position": "top", "formatter": "{c}"}
            }]
        })

        # Biá»ƒu Ä‘á»“ 4: Bar chart hiá»‡u quáº£ hoáº¡t Ä‘á»™ng
        charts_data.append({
            "title": {"text": "Hiá»‡u quáº£ Hoáº¡t Ä‘á»™ng (X9-X14)", "left": "center"},
            "tooltip": {"trigger": "axis"},
            "xAxis": {
                "type": "category",
                "data": ["Tráº£ lÃ£i (X9)", "Tráº£ ná»£ gá»‘c (X10)", "Táº¡o tiá»n (X11)",
                         "VÃ²ng quay HTK (X12)", "Ká»³ thu tiá»n (X13)", "Hiá»‡u suáº¥t TS (X14)"]
            },
            "yAxis": {"type": "value"},
            "series": [{
                "data": [
                    indicators_dict.get('X_9', 0),
                    indicators_dict.get('X_10', 0),
                    indicators_dict.get('X_11', 0),
                    indicators_dict.get('X_12', 0),
                    indicators_dict.get('X_13', 0),
                    indicators_dict.get('X_14', 0)
                ],
                "type": "bar",
                "itemStyle": {"color": "#9C27B0"},
                "label": {"show": True, "position": "top", "formatter": "{c}"}
            }]
        })

        return {
            "status": "success",
            "analysis": analysis,
            "charts_data": charts_data
        }

    except ValueError as e:
        raise HTTPException(
            status_code=400,
            detail=f"KhÃ´ng tÃ¬m tháº¥y GEMINI_API_KEY. Vui lÃ²ng set biáº¿n mÃ´i trÆ°á»ng. Chi tiáº¿t: {str(e)}"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi phÃ¢n tÃ­ch PD káº¿t há»£p: {str(e)}")


@app.get("/model-info")
async def get_model_info():
    """
    Endpoint láº¥y thÃ´ng tin mÃ´ hÃ¬nh hiá»‡n táº¡i

    Returns:
        Dict chá»©a thÃ´ng tin mÃ´ hÃ¬nh
    """
    try:
        if credit_model.model is None:
            # Thá»­ load model tá»« file
            if os.path.exists("model_stacking.pkl"):
                credit_model.load_model("model_stacking.pkl")
            else:
                return {
                    "status": "not_trained",
                    "message": "MÃ´ hÃ¬nh chÆ°a Ä‘Æ°á»£c huáº¥n luyá»‡n"
                }

        return {
            "status": "trained",
            "message": "MÃ´ hÃ¬nh Ä‘Ã£ sáºµn sÃ ng",
            "metrics_train": credit_model.metrics_in,
            "metrics_test": credit_model.metrics_out
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi láº¥y thÃ´ng tin mÃ´ hÃ¬nh: {str(e)}")


@app.post("/chat-assistant")
async def chat_assistant(data: Dict[str, Any]):
    """
    Endpoint chatbot - Trá»£ lÃ½ áº£o tráº£ lá»i cÃ¢u há»i vá» phÃ¢n tÃ­ch

    Args:
        data: Dict chá»©a question, context, indicators, prediction

    Returns:
        Dict chá»©a answer tá»« Gemini
    """
    try:
        question = data.get('question', '')
        context = data.get('context', '')
        indicators = data.get('indicators', {})
        prediction = data.get('prediction', {})

        if not question:
            raise HTTPException(status_code=400, detail="Thiáº¿u cÃ¢u há»i (question)")

        # Láº¥y Gemini analyzer
        analyzer = get_gemini_analyzer()

        # Táº¡o prompt cho chatbot
        prompt = f"""
Báº¡n lÃ  Trá»£ lÃ½ áº£o chuyÃªn nghiá»‡p cá»§a Agribank, chuyÃªn tráº£ lá»i cÃ¡c cÃ¢u há»i vá» phÃ¢n tÃ­ch rá»§i ro tÃ­n dá»¥ng.

**Bá»I Cáº¢NH PHÃ‚N TÃCH TRÆ¯á»šC ÄÃ“:**
{context}

**14 CHá»ˆ Sá» TÃ€I CHÃNH:**
{str(indicators)}

**Káº¾T QUáº¢ Dá»° BÃO PD:**
{str(prediction)}

**CÃ‚U Há»I Cá»¦A NGÆ¯á»œI DÃ™NG:**
{question}

**YÃŠU Cáº¦U TRáº¢ Lá»œI:**
- Tráº£ lá»i ngáº¯n gá»n, chÃ­nh xÃ¡c, dá»… hiá»ƒu (100-200 tá»«)
- Dá»±a trÃªn bá»‘i cáº£nh phÃ¢n tÃ­ch vÃ  dá»¯ liá»‡u Ä‘Ã£ cÃ³
- Náº¿u cÃ¢u há»i liÃªn quan Ä‘áº¿n chá»‰ sá»‘ tÃ i chÃ­nh, giáº£i thÃ­ch rÃµ rÃ ng
- Náº¿u cÃ¢u há»i vá» khuyáº¿n nghá»‹, Ä‘Æ°a ra lá»i khuyÃªn cá»¥ thá»ƒ
- Sá»­ dá»¥ng tiáº¿ng Viá»‡t chuyÃªn nghiá»‡p

HÃ£y tráº£ lá»i cÃ¢u há»i:
"""

        # Gá»i Gemini API
        response = analyzer.model.generate_content(prompt)
        answer = response.text

        return {
            "status": "success",
            "answer": answer
        }

    except ValueError as e:
        raise HTTPException(
            status_code=400,
            detail=f"KhÃ´ng tÃ¬m tháº¥y GEMINI_API_KEY. Chi tiáº¿t: {str(e)}"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi xá»­ lÃ½ cÃ¢u há»i: {str(e)}")


@app.post("/simulate-scenario")
async def simulate_scenario(
    file: Optional[UploadFile] = File(None),
    indicators_json: Optional[str] = Form(None),
    scenario_type: str = Form("mild"),
    custom_revenue: float = Form(0),
    custom_interest: float = Form(0),
    custom_cogs: float = Form(0),
    custom_liquidity: float = Form(0)
):
    """
    Endpoint mÃ´ phá»ng ká»‹ch báº£n xáº¥u - Stress Testing vá»›i tÃ­nh toÃ¡n dÃ¢y chuyá»n hoÃ n chá»‰nh (PhÆ°Æ¡ng Ã¡n A)

    Args:
        file: File XLSX (náº¿u táº£i file má»›i) - Optional
        indicators_json: JSON string chá»©a 14 chá»‰ sá»‘ (náº¿u dÃ¹ng dá»¯ liá»‡u tá»« Tab Dá»± bÃ¡o PD) - Optional
        scenario_type: Loáº¡i ká»‹ch báº£n ("mild", "moderate", "crisis", "custom")
        custom_revenue: % thay Ä‘á»•i doanh thu thuáº§n (chá»‰ dÃ¹ng khi scenario_type="custom")
        custom_interest: % thay Ä‘á»•i lÃ£i suáº¥t vay (chá»‰ dÃ¹ng khi scenario_type="custom")
        custom_cogs: % thay Ä‘á»•i giÃ¡ vá»‘n hÃ ng bÃ¡n (chá»‰ dÃ¹ng khi scenario_type="custom")
        custom_liquidity: % sá»‘c thanh khoáº£n TSNH (chá»‰ dÃ¹ng khi scenario_type="custom")

    Returns:
        Dict chá»©a:
        - indicators_before: 14 chá»‰ sá»‘ trÆ°á»›c khi Ã¡p ká»‹ch báº£n
        - indicators_after: 14 chá»‰ sá»‘ sau khi Ã¡p ká»‹ch báº£n
        - prediction_before: PD trÆ°á»›c khi Ã¡p ká»‹ch báº£n
        - prediction_after: PD sau khi Ã¡p ká»‹ch báº£n
        - pd_change_pct: % thay Ä‘á»•i PD
        - scenario_info: ThÃ´ng tin vá» ká»‹ch báº£n Ä‘Ã£ Ã¡p dá»¥ng
    """
    try:
        import json

        # Kiá»ƒm tra mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c train chÆ°a
        if credit_model.model is None:
            if os.path.exists("model_stacking.pkl"):
                credit_model.load_model("model_stacking.pkl")
            else:
                raise HTTPException(
                    status_code=400,
                    detail="MÃ´ hÃ¬nh chÆ°a Ä‘Æ°á»£c huáº¥n luyá»‡n. Vui lÃ²ng upload file CSV Ä‘á»ƒ huáº¥n luyá»‡n trÆ°á»›c."
                )

        # 1. Láº¤Y 14 CHá»ˆ Sá» BAN Äáº¦U (indicators_before)
        indicators_before = {}

        if file:
            # TrÆ°á»ng há»£p 1: Táº£i file XLSX má»›i
            if not file.filename.endswith(('.xlsx', '.xls')):
                raise HTTPException(status_code=400, detail="File pháº£i cÃ³ Ä‘á»‹nh dáº¡ng XLSX hoáº·c XLS")

            # LÆ°u file táº¡m
            with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp_file:
                content = await file.read()
                tmp_file.write(content)
                tmp_file_path = tmp_file.name

            try:
                # Äá»c file XLSX vÃ  tÃ­nh 14 chá»‰ sá»‘
                excel_processor.read_excel(tmp_file_path)
                indicators_before = excel_processor.calculate_14_indicators()
            finally:
                try:
                    os.unlink(tmp_file_path)
                except Exception:
                    pass

        elif indicators_json:
            # TrÆ°á»ng há»£p 2: Sá»­ dá»¥ng dá»¯ liá»‡u tá»« Tab Dá»± bÃ¡o PD
            indicators_before = json.loads(indicators_json)
        else:
            raise HTTPException(
                status_code=400,
                detail="Vui lÃ²ng cung cáº¥p file XLSX hoáº·c dá»¯ liá»‡u tá»« Tab Dá»± bÃ¡o PD"
            )

        # 2. XÃC Äá»ŠNH % BIáº¾N Äá»˜NG THEO Ká»ŠCH Báº¢N (PHÆ¯Æ NG ÃN A - STRESS TESTING)
        scenario_configs = {
            "mild": {
                "name": "ğŸŸ  Kinh táº¿ giáº£m nháº¹",
                "revenue_change": -5,
                "interest_rate_change": 10,
                "cogs_change": 3,
                "liquidity_shock": -5
            },
            "moderate": {
                "name": "ğŸ”´ CÃº sá»‘c kinh táº¿ trung bÃ¬nh",
                "revenue_change": -12,
                "interest_rate_change": 25,
                "cogs_change": 8,
                "liquidity_shock": -12
            },
            "crisis": {
                "name": "âš« Khá»§ng hoáº£ng",
                "revenue_change": -25,
                "interest_rate_change": 40,
                "cogs_change": 15,
                "liquidity_shock": -25
            },
            "custom": {
                "name": "ğŸŸ¡ TÃ¹y chá»n biáº¿n Ä‘á»™ng",
                "revenue_change": custom_revenue,
                "interest_rate_change": custom_interest,
                "cogs_change": custom_cogs,
                "liquidity_shock": custom_liquidity
            }
        }

        if scenario_type not in scenario_configs:
            raise HTTPException(
                status_code=400,
                detail=f"Loáº¡i ká»‹ch báº£n khÃ´ng há»£p lá»‡. Chá»n: {', '.join(scenario_configs.keys())}"
            )

        scenario = scenario_configs[scenario_type]

        # 3. TÃNH 14 CHá»ˆ Sá» SAU KHI ÃP Ká»ŠCH Báº¢N (indicators_after)
        # Sá»­ dá»¥ng PHÆ¯Æ NG ÃN A: Stress Testing vá»›i tÃ­nh toÃ¡n dÃ¢y chuyá»n hoÃ n chá»‰nh
        indicators_after = excel_processor.simulate_scenario_full_propagation(
            original_indicators=indicators_before,
            revenue_change_pct=scenario["revenue_change"],
            interest_rate_change_pct=scenario["interest_rate_change"],
            cogs_change_pct=scenario["cogs_change"],
            liquidity_shock_pct=scenario["liquidity_shock"]
        )

        # 4. Dá»° BÃO PD TRÆ¯á»šC VÃ€ SAU
        # Dá»± bÃ¡o PD trÆ°á»›c khi Ã¡p ká»‹ch báº£n
        X_before = pd.DataFrame([indicators_before])
        prediction_before = credit_model.predict(X_before)

        # Dá»± bÃ¡o PD sau khi Ã¡p ká»‹ch báº£n
        X_after = pd.DataFrame([indicators_after])
        prediction_after = credit_model.predict(X_after)

        # 5. TÃNH % THAY Äá»”I PD
        pd_before = prediction_before["pd_stacking"]
        pd_after = prediction_after["pd_stacking"]
        pd_change_pct = ((pd_after - pd_before) / pd_before * 100) if pd_before != 0 else 0

        # 6. CHUáº¨N Bá»Š Káº¾T QUáº¢ TRáº¢ Vá»€
        # Chuyá»ƒn Ä‘á»•i indicators thÃ nh list cÃ³ tÃªn
        def indicators_to_list(indicators_dict):
            indicator_names = {
                'X_1': 'Há»‡ sá»‘ biÃªn lá»£i nhuáº­n gá»™p',
                'X_2': 'Há»‡ sá»‘ biÃªn lá»£i nhuáº­n trÆ°á»›c thuáº¿',
                'X_3': 'Tá»· suáº¥t lá»£i nhuáº­n trÆ°á»›c thuáº¿ trÃªn tá»•ng tÃ i sáº£n (ROA)',
                'X_4': 'Tá»· suáº¥t lá»£i nhuáº­n trÆ°á»›c thuáº¿ trÃªn vá»‘n chá»§ sá»Ÿ há»¯u (ROE)',
                'X_5': 'Há»‡ sá»‘ ná»£ trÃªn tÃ i sáº£n',
                'X_6': 'Há»‡ sá»‘ ná»£ trÃªn vá»‘n chá»§ sá»Ÿ há»¯u',
                'X_7': 'Kháº£ nÄƒng thanh toÃ¡n hiá»‡n hÃ nh',
                'X_8': 'Kháº£ nÄƒng thanh toÃ¡n nhanh',
                'X_9': 'Há»‡ sá»‘ kháº£ nÄƒng tráº£ lÃ£i',
                'X_10': 'Há»‡ sá»‘ kháº£ nÄƒng tráº£ ná»£ gá»‘c',
                'X_11': 'Há»‡ sá»‘ kháº£ nÄƒng táº¡o tiá»n trÃªn vá»‘n chá»§ sá»Ÿ há»¯u',
                'X_12': 'VÃ²ng quay hÃ ng tá»“n kho',
                'X_13': 'Ká»³ thu tiá»n bÃ¬nh quÃ¢n',
                'X_14': 'Hiá»‡u suáº¥t sá»­ dá»¥ng tÃ i sáº£n'
            }
            result = []
            for key, value in indicators_dict.items():
                result.append({
                    'code': key,
                    'name': indicator_names[key],
                    'value': value
                })
            return result

        return {
            "status": "success",
            "scenario_info": {
                "type": scenario_type,
                "name": scenario["name"],
                "changes": {
                    "revenue": scenario["revenue_change"],
                    "interest": scenario["interest_rate_change"],
                    "cogs": scenario["cogs_change"],
                    "liquidity": scenario["liquidity_shock"]
                }
            },
            "indicators_before": indicators_to_list(indicators_before),
            "indicators_before_dict": indicators_before,
            "indicators_after": indicators_to_list(indicators_after),
            "indicators_after_dict": indicators_after,
            "prediction_before": prediction_before,
            "prediction_after": prediction_after,
            "pd_change": {
                "before": pd_before,
                "after": pd_after,
                "change_pct": round(pd_change_pct, 2),
                "change_absolute": round(pd_after - pd_before, 6)
            }
        }

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi mÃ´ phá»ng ká»‹ch báº£n: {str(e)}")


@app.post("/analyze-scenario")
async def analyze_scenario(request_data: Dict[str, Any]):
    """
    Endpoint phÃ¢n tÃ­ch káº¿t quáº£ mÃ´ phá»ng ká»‹ch báº£n báº±ng Gemini API

    Args:
        request_data: Dict chá»©a káº¿t quáº£ mÃ´ phá»ng ká»‹ch báº£n

    Returns:
        Dict chá»©a káº¿t quáº£ phÃ¢n tÃ­ch tá»« Gemini
    """
    try:
        # Láº¥y Gemini analyzer
        analyzer = get_gemini_analyzer()

        # PhÃ¢n tÃ­ch ká»‹ch báº£n
        analysis = analyzer.analyze_scenario_simulation(request_data)

        return {
            "status": "success",
            "analysis": analysis
        }

    except ValueError as e:
        raise HTTPException(
            status_code=400,
            detail=f"KhÃ´ng tÃ¬m tháº¥y GEMINI_API_KEY. Vui lÃ²ng set biáº¿n mÃ´i trÆ°á»ng. Chi tiáº¿t: {str(e)}"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi phÃ¢n tÃ­ch ká»‹ch báº£n báº±ng Gemini: {str(e)}")


@app.post("/simulate-scenario-macro")
async def simulate_scenario_macro(
    file: Optional[UploadFile] = File(None),
    indicators_json: Optional[str] = Form(None),
    scenario_type: str = Form("recession_mild"),
    industry_code: str = Form("manufacturing"),
    custom_gdp: float = Form(0),
    custom_cpi: float = Form(0),
    custom_ppi: float = Form(0),
    custom_policy_rate: float = Form(0),
    custom_fx: float = Form(0)
):
    """
    Endpoint mÃ´ phá»ng ká»‹ch báº£n vÄ© mÃ´ (Macro Stress Testing)

    Args:
        file: File XLSX (náº¿u táº£i file má»›i) - Optional
        indicators_json: JSON string chá»©a 14 chá»‰ sá»‘ (náº¿u dÃ¹ng dá»¯ liá»‡u tá»« Tab Dá»± bÃ¡o PD) - Optional
        scenario_type: Loáº¡i ká»‹ch báº£n ("recession_mild", "recession_moderate", "crisis", "custom")
        industry_code: MÃ£ ngÃ nh ("manufacturing", "export", "retail")
        custom_gdp: % tÄƒng trÆ°á»Ÿng GDP (chá»‰ dÃ¹ng khi scenario_type="custom")
        custom_cpi: % láº¡m phÃ¡t CPI (chá»‰ dÃ¹ng khi scenario_type="custom")
        custom_ppi: % láº¡m phÃ¡t PPI (chá»‰ dÃ¹ng khi scenario_type="custom")
        custom_policy_rate: Thay Ä‘á»•i lÃ£i suáº¥t NHNN bps (chá»‰ dÃ¹ng khi scenario_type="custom")
        custom_fx: % thay Ä‘á»•i tá»· giÃ¡ USD/VND (chá»‰ dÃ¹ng khi scenario_type="custom")

    Returns:
        Dict chá»©a:
        - macro_variables: 5 biáº¿n vÄ© mÃ´ Ä‘Ã£ chá»n
        - micro_shocks: 4 biáº¿n vi mÃ´ Ä‘Æ°á»£c tÃ­nh tá»« kÃªnh truyá»n dáº«n
        - indicators_before: 14 chá»‰ sá»‘ trÆ°á»›c khi Ã¡p ká»‹ch báº£n
        - indicators_after: 14 chá»‰ sá»‘ sau khi Ã¡p ká»‹ch báº£n
        - prediction_before: PD trÆ°á»›c khi Ã¡p ká»‹ch báº£n
        - prediction_after: PD sau khi Ã¡p ká»‹ch báº£n
        - pd_change_pct: % thay Ä‘á»•i PD
        - scenario_info: ThÃ´ng tin vá» ká»‹ch báº£n Ä‘Ã£ Ã¡p dá»¥ng
    """
    try:
        import json

        # Kiá»ƒm tra mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c train chÆ°a
        if credit_model.model is None:
            if os.path.exists("model_stacking.pkl"):
                credit_model.load_model("model_stacking.pkl")
            else:
                raise HTTPException(
                    status_code=400,
                    detail="MÃ´ hÃ¬nh chÆ°a Ä‘Æ°á»£c huáº¥n luyá»‡n. Vui lÃ²ng upload file CSV Ä‘á»ƒ huáº¥n luyá»‡n trÆ°á»›c."
                )

        # 1. Láº¤Y 14 CHá»ˆ Sá» BAN Äáº¦U (indicators_before)
        indicators_before = {}

        if file:
            # TrÆ°á»ng há»£p 1: Táº£i file XLSX má»›i
            if not file.filename.endswith(('.xlsx', '.xls')):
                raise HTTPException(status_code=400, detail="File pháº£i cÃ³ Ä‘á»‹nh dáº¡ng XLSX hoáº·c XLS")

            # LÆ°u file táº¡m
            with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp_file:
                content = await file.read()
                tmp_file.write(content)
                tmp_file_path = tmp_file.name

            try:
                # Äá»c file XLSX vÃ  tÃ­nh 14 chá»‰ sá»‘
                excel_processor.read_excel(tmp_file_path)
                indicators_before = excel_processor.calculate_14_indicators()
            finally:
                try:
                    os.unlink(tmp_file_path)
                except Exception:
                    pass

        elif indicators_json:
            # TrÆ°á»ng há»£p 2: Sá»­ dá»¥ng dá»¯ liá»‡u tá»« Tab Dá»± bÃ¡o PD
            indicators_before = json.loads(indicators_json)
        else:
            raise HTTPException(
                status_code=400,
                detail="Vui lÃ²ng cung cáº¥p file XLSX hoáº·c dá»¯ liá»‡u tá»« Tab Dá»± bÃ¡o PD"
            )

        # 2. XÃC Äá»ŠNH 5 BIáº¾N VÄ¨ MÃ” THEO Ká»ŠCH Báº¢N
        macro_scenario_configs = {
            "recession_mild": {
                "name": "ğŸŸ  Suy thoÃ¡i nháº¹",
                "gdp_growth_pct": -1.5,
                "inflation_cpi_pct": 6.0,
                "inflation_ppi_pct": 8.0,
                "policy_rate_change_bps": 100,
                "fx_usd_vnd_pct": 3.0
            },
            "recession_moderate": {
                "name": "ğŸ”´ Suy thoÃ¡i trung bÃ¬nh",
                "gdp_growth_pct": -3.5,
                "inflation_cpi_pct": 10.0,
                "inflation_ppi_pct": 14.0,
                "policy_rate_change_bps": 200,
                "fx_usd_vnd_pct": 6.0
            },
            "crisis": {
                "name": "âš« Khá»§ng hoáº£ng",
                "gdp_growth_pct": -6.0,
                "inflation_cpi_pct": 15.0,
                "inflation_ppi_pct": 20.0,
                "policy_rate_change_bps": 300,
                "fx_usd_vnd_pct": 10.0
            },
            "custom": {
                "name": "ğŸŸ¡ TÃ¹y chá»‰nh vÄ© mÃ´",
                "gdp_growth_pct": custom_gdp,
                "inflation_cpi_pct": custom_cpi,
                "inflation_ppi_pct": custom_ppi,
                "policy_rate_change_bps": custom_policy_rate,
                "fx_usd_vnd_pct": custom_fx
            }
        }

        if scenario_type not in macro_scenario_configs:
            raise HTTPException(
                status_code=400,
                detail=f"Loáº¡i ká»‹ch báº£n khÃ´ng há»£p lá»‡. Chá»n: {', '.join(macro_scenario_configs.keys())}"
            )

        macro_scenario = macro_scenario_configs[scenario_type]

        # 3. KÃŠNH TRUYá»€N DáºªN: MACRO â†’ MICRO
        # Gá»i function macro_to_micro_transmission()
        micro_shocks = excel_processor.macro_to_micro_transmission(
            gdp_growth_pct=macro_scenario["gdp_growth_pct"],
            inflation_cpi_pct=macro_scenario["inflation_cpi_pct"],
            inflation_ppi_pct=macro_scenario["inflation_ppi_pct"],
            policy_rate_change_bps=macro_scenario["policy_rate_change_bps"],
            fx_usd_vnd_pct=macro_scenario["fx_usd_vnd_pct"],
            industry_code=industry_code
        )

        # 4. TÃNH 14 CHá»ˆ Sá» SAU KHI ÃP 4 BIáº¾N VI MÃ”
        # Sá»­ dá»¥ng simulate_scenario_full_propagation() vá»›i 4 biáº¿n vi mÃ´
        indicators_after = excel_processor.simulate_scenario_full_propagation(
            original_indicators=indicators_before,
            revenue_change_pct=micro_shocks["revenue_change_pct"],
            interest_rate_change_pct=micro_shocks["interest_rate_change_pct"],
            cogs_change_pct=micro_shocks["cogs_change_pct"],
            liquidity_shock_pct=micro_shocks["liquidity_shock_pct"]
        )

        # 5. Dá»° BÃO PD TRÆ¯á»šC VÃ€ SAU
        # Dá»± bÃ¡o PD trÆ°á»›c khi Ã¡p ká»‹ch báº£n
        X_before = pd.DataFrame([indicators_before])
        prediction_before = credit_model.predict(X_before)

        # Dá»± bÃ¡o PD sau khi Ã¡p ká»‹ch báº£n
        X_after = pd.DataFrame([indicators_after])
        prediction_after = credit_model.predict(X_after)

        # 6. TÃNH % THAY Äá»”I PD
        pd_before = prediction_before["pd_stacking"]
        pd_after = prediction_after["pd_stacking"]
        pd_change_pct = ((pd_after - pd_before) / pd_before * 100) if pd_before != 0 else 0

        # 7. CHUáº¨N Bá»Š Káº¾T QUáº¢ TRáº¢ Vá»€
        # Chuyá»ƒn Ä‘á»•i indicators thÃ nh list cÃ³ tÃªn
        def indicators_to_list(indicators_dict):
            indicator_names = {
                'X_1': 'Há»‡ sá»‘ biÃªn lá»£i nhuáº­n gá»™p',
                'X_2': 'Há»‡ sá»‘ biÃªn lá»£i nhuáº­n trÆ°á»›c thuáº¿',
                'X_3': 'Tá»· suáº¥t lá»£i nhuáº­n trÆ°á»›c thuáº¿ trÃªn tá»•ng tÃ i sáº£n (ROA)',
                'X_4': 'Tá»· suáº¥t lá»£i nhuáº­n trÆ°á»›c thuáº¿ trÃªn vá»‘n chá»§ sá»Ÿ há»¯u (ROE)',
                'X_5': 'Há»‡ sá»‘ ná»£ trÃªn tÃ i sáº£n',
                'X_6': 'Há»‡ sá»‘ ná»£ trÃªn vá»‘n chá»§ sá»Ÿ há»¯u',
                'X_7': 'Kháº£ nÄƒng thanh toÃ¡n hiá»‡n hÃ nh',
                'X_8': 'Kháº£ nÄƒng thanh toÃ¡n nhanh',
                'X_9': 'Há»‡ sá»‘ kháº£ nÄƒng tráº£ lÃ£i',
                'X_10': 'Há»‡ sá»‘ kháº£ nÄƒng tráº£ ná»£ gá»‘c',
                'X_11': 'Há»‡ sá»‘ kháº£ nÄƒng táº¡o tiá»n trÃªn vá»‘n chá»§ sá»Ÿ há»¯u',
                'X_12': 'VÃ²ng quay hÃ ng tá»“n kho',
                'X_13': 'Ká»³ thu tiá»n bÃ¬nh quÃ¢n',
                'X_14': 'Hiá»‡u suáº¥t sá»­ dá»¥ng tÃ i sáº£n'
            }
            result = []
            for key, value in indicators_dict.items():
                result.append({
                    'code': key,
                    'name': indicator_names[key],
                    'value': value
                })
            return result

        # TÃªn ngÃ nh nghá»
        industry_names = {
            "manufacturing": "Sáº£n xuáº¥t",
            "export": "Xuáº¥t kháº©u",
            "retail": "BÃ¡n láº»"
        }

        return {
            "status": "success",
            "scenario_info": {
                "type": scenario_type,
                "name": macro_scenario["name"],
                "industry": industry_names.get(industry_code, industry_code)
            },
            "macro_variables": {
                "gdp_growth_pct": macro_scenario["gdp_growth_pct"],
                "inflation_cpi_pct": macro_scenario["inflation_cpi_pct"],
                "inflation_ppi_pct": macro_scenario["inflation_ppi_pct"],
                "policy_rate_change_bps": macro_scenario["policy_rate_change_bps"],
                "fx_usd_vnd_pct": macro_scenario["fx_usd_vnd_pct"]
            },
            "micro_shocks": micro_shocks,
            "indicators_before": indicators_to_list(indicators_before),
            "indicators_before_dict": indicators_before,
            "indicators_after": indicators_to_list(indicators_after),
            "indicators_after_dict": indicators_after,
            "prediction_before": prediction_before,
            "prediction_after": prediction_after,
            "pd_change": {
                "before": pd_before,
                "after": pd_after,
                "change_pct": round(pd_change_pct, 2),
                "change_absolute": round(pd_after - pd_before, 6)
            }
        }

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi mÃ´ phá»ng ká»‹ch báº£n vÄ© mÃ´: {str(e)}")


@app.post("/analyze-macro")
async def analyze_macro(request_data: Dict[str, Any]):
    """
    Endpoint phÃ¢n tÃ­ch káº¿t quáº£ mÃ´ phá»ng vÄ© mÃ´ báº±ng Gemini API

    Args:
        request_data: Dict chá»©a káº¿t quáº£ mÃ´ phá»ng vÄ© mÃ´

    Returns:
        Dict chá»©a káº¿t quáº£ phÃ¢n tÃ­ch tá»« Gemini
    """
    try:
        # Láº¥y Gemini analyzer
        analyzer = get_gemini_analyzer()

        # Láº¥y thÃ´ng tin tá»« request
        scenario_info = request_data.get('scenario_info', {})
        macro_variables = request_data.get('macro_variables', {})
        micro_shocks = request_data.get('micro_shocks', {})
        indicators_before = request_data.get('indicators_before_dict', {})
        indicators_after = request_data.get('indicators_after_dict', {})
        pd_change = request_data.get('pd_change', {})

        # Táº¡o prompt cho Gemini
        prompt = f"""
Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch kinh táº¿ vÄ© mÃ´ vÃ  rá»§i ro tÃ­n dá»¥ng cá»§a Agribank. HÃ£y phÃ¢n tÃ­ch káº¿t quáº£ mÃ´ phá»ng ká»‹ch báº£n vÄ© mÃ´ dÆ°á»›i Ä‘Ã¢y.

**THÃ”NG TIN Ká»ŠCH Báº¢N VÄ¨ MÃ”:**

**Ká»‹ch báº£n:** {scenario_info.get('name', 'N/A')}
**NgÃ nh:** {scenario_info.get('industry', 'N/A')}

**5 BIáº¾N VÄ¨ MÃ”:**
- TÄƒng trÆ°á»Ÿng GDP: {macro_variables.get('gdp_growth_pct', 0):.1f}%
- Láº¡m phÃ¡t CPI: {macro_variables.get('inflation_cpi_pct', 0):.1f}%
- Láº¡m phÃ¡t PPI: {macro_variables.get('inflation_ppi_pct', 0):.1f}%
- Thay Ä‘á»•i lÃ£i suáº¥t NHNN: {macro_variables.get('policy_rate_change_bps', 0):.0f} bps
- Thay Ä‘á»•i tá»· giÃ¡ USD/VND: {macro_variables.get('fx_usd_vnd_pct', 0):.1f}%

**4 BIáº¾N VI MÃ” (KÃªnh truyá»n dáº«n):**
- Thay Ä‘á»•i doanh thu: {micro_shocks.get('revenue_change_pct', 0):.2f}%
- Thay Ä‘á»•i lÃ£i suáº¥t vay: {micro_shocks.get('interest_rate_change_pct', 0):.2f}%
- Thay Ä‘á»•i giÃ¡ vá»‘n hÃ ng bÃ¡n: {micro_shocks.get('cogs_change_pct', 0):.2f}%
- Sá»‘c thanh khoáº£n: {micro_shocks.get('liquidity_shock_pct', 0):.2f}%

**TÃC Äá»˜NG Äáº¾N XÃC SUáº¤T Vá»  Ná»¢:**
- PD trÆ°á»›c: {pd_change.get('before', 0):.4f}
- PD sau: {pd_change.get('after', 0):.4f}
- Thay Ä‘á»•i: {pd_change.get('change_pct', 0):.2f}% (tuyá»‡t Ä‘á»‘i: {pd_change.get('change_absolute', 0):.4f})

**YÃŠU Cáº¦U PHÃ‚N TÃCH:**

HÃ£y viáº¿t bÃ¡o cÃ¡o phÃ¢n tÃ­ch chi tiáº¿t (sá»­ dá»¥ng Markdown) vá»›i cáº¥u trÃºc sau:

## ğŸ“Š Tá»”NG QUAN Ká»ŠCH Báº¢N VÄ¨ MÃ”
(2-3 cÃ¢u mÃ´ táº£ ká»‹ch báº£n vÄ© mÃ´ vÃ  má»©c Ä‘á»™ nghiÃªm trá»ng)

## ğŸ”„ PHÃ‚N TÃCH KÃŠNH TRUYá»€N DáºªN
(Giáº£i thÃ­ch cÃ¡ch 5 biáº¿n vÄ© mÃ´ tÃ¡c Ä‘á»™ng lÃªn 4 biáº¿n vi mÃ´ cá»§a doanh nghiá»‡p)

### TÃ¡c Ä‘á»™ng lÃªn Doanh thu
(PhÃ¢n tÃ­ch chi tiáº¿t)

### TÃ¡c Ä‘á»™ng lÃªn Chi phÃ­ & LÃ£i suáº¥t
(PhÃ¢n tÃ­ch chi tiáº¿t)

### TÃ¡c Ä‘á»™ng lÃªn Thanh khoáº£n
(PhÃ¢n tÃ­ch chi tiáº¿t)

## ğŸ“ˆ ÄÃNH GIÃ TÃC Äá»˜NG Äáº¾N PD

### Má»©c Ä‘á»™ thay Ä‘á»•i
(PhÃ¢n tÃ­ch má»©c Ä‘á»™ thay Ä‘á»•i PD: nháº¹/trung bÃ¬nh/nghiÃªm trá»ng)

### CÃ¡c chá»‰ sá»‘ tÃ i chÃ­nh chá»‹u áº£nh hÆ°á»Ÿng nhiá»u nháº¥t
(Liá»‡t kÃª 3-5 chá»‰ sá»‘ bá»‹ áº£nh hÆ°á»Ÿng máº¡nh nháº¥t)

## ğŸ’¡ KHUYáº¾N NGHá»Š

### Äá»‘i vá»›i Doanh nghiá»‡p
(2-3 khuyáº¿n nghá»‹ cá»¥ thá»ƒ)

### Äá»‘i vá»›i NgÃ¢n hÃ ng
(2-3 khuyáº¿n nghá»‹ vá» chÃ­nh sÃ¡ch tÃ­n dá»¥ng)

## âš ï¸ Rá»¦I RO Cáº¦N LÆ¯U Ã
(Liá»‡t kÃª 2-3 rá»§i ro tiá»m áº©n cáº§n theo dÃµi)

---
**LÆ°u Ã½:** Viáº¿t ngáº¯n gá»n, chuyÃªn nghiá»‡p, dá»… hiá»ƒu. Táº­p trung vÃ o insights vÃ  actionable recommendations.
"""

        # Gá»i Gemini API
        response = analyzer.model.generate_content(prompt)
        analysis = response.text

        return {
            "status": "success",
            "analysis": analysis
        }

    except ValueError as e:
        raise HTTPException(
            status_code=400,
            detail=f"KhÃ´ng tÃ¬m tháº¥y GEMINI_API_KEY. Vui lÃ²ng set biáº¿n mÃ´i trÆ°á»ng. Chi tiáº¿t: {str(e)}"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi phÃ¢n tÃ­ch vÄ© mÃ´ báº±ng Gemini: {str(e)}")


@app.post("/train-early-warning")
async def train_early_warning_model(file: UploadFile = File(...)):
    """
    Endpoint huáº¥n luyá»‡n Early Warning System

    Args:
        file: File Excel chá»©a 1300 DN vá»›i 14 chá»‰ sá»‘ (X_1 â†’ X_14) + cá»™t 'label' (0=khÃ´ng vá»¡ ná»£, 1=vá»¡ ná»£)

    Returns:
        Dict chá»©a thÃ´ng tin vá» training:
        - status: success
        - num_samples: Sá»‘ lÆ°á»£ng máº«u
        - feature_importances: Feature importances tá»« RandomForest
        - cluster_distribution: PhÃ¢n bá»‘ cÃ¡c cluster
    """
    try:
        # Kiá»ƒm tra file extension
        if not file.filename.endswith(('.xlsx', '.xls', '.csv')):
            raise HTTPException(
                status_code=400,
                detail="File pháº£i cÃ³ Ä‘á»‹nh dáº¡ng XLSX, XLS hoáº·c CSV"
            )

        # LÆ°u file táº¡m
        suffix = '.xlsx' if file.filename.endswith(('.xlsx', '.xls')) else '.csv'
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp_file:
            content = await file.read()
            tmp_file.write(content)
            tmp_file_path = tmp_file.name

        try:
            # Äá»c file
            if suffix == '.csv':
                df = pd.read_csv(tmp_file_path)
            else:
                df = pd.read_excel(tmp_file_path)

            # Kiá»ƒm tra cÃ¡c cá»™t cáº§n thiáº¿t
            required_cols = [f'X_{i}' for i in range(1, 15)] + ['label']
            missing_cols = [col for col in required_cols if col not in df.columns]

            if missing_cols:
                raise HTTPException(
                    status_code=400,
                    detail=f"File thiáº¿u cÃ¡c cá»™t: {', '.join(missing_cols)}"
                )

            # Train Early Warning System
            result = early_warning_system.train_models(df)

            response_data = {
                "status": "success",
                "message": "Early Warning System trained successfully!",
                **result
            }

            return convert_to_json_serializable(response_data)

        finally:
            # XÃ³a file táº¡m
            try:
                os.unlink(tmp_file_path)
            except Exception:
                pass

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi train Early Warning System: {str(e)}")


@app.post("/early-warning-check")
async def early_warning_check(
    file: Optional[UploadFile] = File(None),
    indicators_json: Optional[str] = Form(None),
    report_period: Optional[str] = Form(None),
    industry_code: str = Form("manufacturing")
):
    """
    Endpoint kiá»ƒm tra cáº£nh bÃ¡o rá»§i ro sá»›m

    Args:
        file: File Excel (náº¿u táº£i file má»›i) - Optional
        indicators_json: JSON string chá»©a 14 chá»‰ sá»‘ (náº¿u dÃ¹ng dá»¯ liá»‡u tá»« Tab Dá»± bÃ¡o PD) - Optional
        report_period: Ká»³ bÃ¡o cÃ¡o (QuÃ½/6 thÃ¡ng/NÄƒm) - Optional, chá»‰ Ä‘á»ƒ hiá»ƒn thá»‹
        industry_code: MÃ£ ngÃ nh ("manufacturing", "export", "retail")

    Returns:
        Dict chá»©a:
        - health_score: Health Score (0-100)
        - risk_level: Má»©c rá»§i ro (Safe/Watch/Warning/Alert)
        - risk_level_color: MÃ u sáº¯c
        - current_pd: PD hiá»‡n táº¡i
        - top_weaknesses: Top 3 Ä‘iá»ƒm yáº¿u
        - cluster_info: ThÃ´ng tin cluster
        - pd_projection: Dá»± bÃ¡o PD tÆ°Æ¡ng lai
        - gemini_diagnosis: BÃ¡o cÃ¡o cháº©n Ä‘oÃ¡n tá»« Gemini AI
        - feature_importances: Feature importances
    """
    try:
        import json

        # Kiá»ƒm tra Early Warning System Ä‘Ã£ Ä‘Æ°á»£c train chÆ°a
        if early_warning_system.stacking_model is None:
            raise HTTPException(
                status_code=400,
                detail="Early Warning System chÆ°a Ä‘Æ°á»£c train. Vui lÃ²ng upload file training data trÆ°á»›c."
            )

        # Kiá»ƒm tra mÃ´ hÃ¬nh PD Ä‘Ã£ Ä‘Æ°á»£c train chÆ°a
        if credit_model.model is None:
            if os.path.exists("model_stacking.pkl"):
                credit_model.load_model("model_stacking.pkl")
            else:
                raise HTTPException(
                    status_code=400,
                    detail="MÃ´ hÃ¬nh PD chÆ°a Ä‘Æ°á»£c huáº¥n luyá»‡n. Vui lÃ²ng train mÃ´ hÃ¬nh trÆ°á»›c."
                )

        # 1. Láº¤Y 14 CHá»ˆ Sá»
        indicators = {}

        if file:
            # TrÆ°á»ng há»£p 1: Táº£i file XLSX má»›i
            if not file.filename.endswith(('.xlsx', '.xls')):
                raise HTTPException(status_code=400, detail="File pháº£i cÃ³ Ä‘á»‹nh dáº¡ng XLSX hoáº·c XLS")

            # LÆ°u file táº¡m
            with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp_file:
                content = await file.read()
                tmp_file.write(content)
                tmp_file_path = tmp_file.name

            try:
                # Äá»c file XLSX vÃ  tÃ­nh 14 chá»‰ sá»‘
                excel_processor.read_excel(tmp_file_path)
                indicators = excel_processor.calculate_14_indicators()
            finally:
                try:
                    os.unlink(tmp_file_path)
                except Exception:
                    pass

        elif indicators_json:
            # TrÆ°á»ng há»£p 2: Sá»­ dá»¥ng dá»¯ liá»‡u tá»« Tab Dá»± bÃ¡o PD
            indicators = json.loads(indicators_json)
        else:
            raise HTTPException(
                status_code=400,
                detail="Vui lÃ²ng cung cáº¥p file XLSX hoáº·c dá»¯ liá»‡u tá»« Tab Dá»± bÃ¡o PD"
            )

        # 2. TÃNH HEALTH SCORE
        health_score = early_warning_system.calculate_health_score(indicators)

        # 3. PHÃ‚N LOáº I Má»¨C Rá»¦I RO
        risk_info = early_warning_system.classify_risk_level(health_score)

        # 4. TÃNH PD HIá»†N Táº I (sá»­ dá»¥ng early_warning_system.stacking_model)
        feature_cols = [f'X_{i}' for i in range(1, 15)]
        X_current = [[indicators[col] for col in feature_cols]]
        current_pd = early_warning_system.stacking_model.predict_proba(X_current)[0, 1] * 100

        # 5. PHÃT HIá»†N ÄIá»‚M Yáº¾U
        weaknesses = early_warning_system.detect_weaknesses(indicators)

        # 6. XÃC Äá»ŠNH Vá»Š TRÃ CLUSTER
        cluster_info = early_warning_system.get_cluster_position(indicators)

        # 7. Dá»° BÃO PD TÆ¯Æ NG LAI (3/6/12 thÃ¡ng x 3 ká»‹ch báº£n)
        scenarios = ['recession_mild', 'recession_moderate', 'crisis']
        time_periods = [3, 6, 12]

        pd_projection = {
            'current': current_pd
        }

        for scenario in scenarios:
            pd_projection[scenario] = {}
            for months in time_periods:
                pd_future = early_warning_system.project_future_pd(
                    indicators=indicators,
                    months=months,
                    scenario=scenario,
                    excel_processor=excel_processor,
                    industry_code=industry_code
                )
                pd_projection[scenario][f'{months}_months'] = pd_future

        # 8. Táº O BÃO CÃO CHáº¨N ÄOÃN Báº°NG GEMINI AI
        gemini_diagnosis = early_warning_system.generate_gemini_diagnosis(
            health_score=health_score,
            risk_info=risk_info,
            weaknesses=weaknesses,
            cluster_info=cluster_info,
            pd_projections=pd_projection,
            current_pd=current_pd,
            gemini_api_key=GEMINI_API_KEY
        )

        # 9. TRáº¢ Vá»€ Káº¾T QUáº¢
        response_data = {
            "status": "success",
            "health_score": health_score,
            "risk_level": risk_info['risk_level'],
            "risk_level_color": risk_info['risk_level_color'],
            "risk_level_icon": risk_info['risk_level_icon'],
            "risk_level_text": risk_info['risk_level_text'],
            "current_pd": current_pd,
            "top_weaknesses": weaknesses,
            "cluster_info": cluster_info,
            "pd_projection": pd_projection,
            "gemini_diagnosis": gemini_diagnosis,
            "feature_importances": early_warning_system.feature_importances,
            "report_period": report_period,
            "indicators": indicators  # ThÃªm 14 chá»‰ sá»‘ Ä‘á»ƒ frontend cÃ³ thá»ƒ váº½ biá»ƒu Ä‘á»“ radar
        }

        return convert_to_json_serializable(response_data)

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi kiá»ƒm tra cáº£nh bÃ¡o rá»§i ro: {str(e)}")


@app.post("/train-anomaly")
async def train_anomaly_model(file: UploadFile = File(...)):
    """
    Endpoint huáº¥n luyá»‡n Anomaly Detection System

    Args:
        file: File Excel/CSV chá»©a 1300 DN vá»›i 14 chá»‰ sá»‘ (X_1 â†’ X_14) + cá»™t 'label' (0=khá»e máº¡nh, 1=vá»¡ ná»£)

    Returns:
        Dict chá»©a thÃ´ng tin vá» training:
        - status: success
        - feature_statistics: Thá»‘ng kÃª 14 features (P5, P25, P50, P75, P95)
        - contamination_rate: Tá»· lá»‡ contamination
    """
    try:
        # Kiá»ƒm tra file extension
        if not file.filename.endswith(('.xlsx', '.xls', '.csv')):
            raise HTTPException(
                status_code=400,
                detail="File pháº£i cÃ³ Ä‘á»‹nh dáº¡ng XLSX, XLS hoáº·c CSV"
            )

        # LÆ°u file táº¡m
        suffix = '.xlsx' if file.filename.endswith(('.xlsx', '.xls')) else '.csv'
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp_file:
            content = await file.read()
            tmp_file.write(content)
            tmp_file_path = tmp_file.name

        try:
            # Äá»c file
            if suffix == '.csv':
                df = pd.read_csv(tmp_file_path)
            else:
                df = pd.read_excel(tmp_file_path)

            # Kiá»ƒm tra cÃ¡c cá»™t cáº§n thiáº¿t
            required_cols = [f'X_{i}' for i in range(1, 15)] + ['label']
            missing_cols = [col for col in required_cols if col not in df.columns]

            if missing_cols:
                raise HTTPException(
                    status_code=400,
                    detail=f"File thiáº¿u cÃ¡c cá»™t: {', '.join(missing_cols)}"
                )

            # Train Anomaly Detection System
            result = anomaly_system.train_model(df)

            response_data = {
                "status": "success",
                "message": "Anomaly Detection System trained successfully!",
                **result
            }

            return convert_to_json_serializable(response_data)

        finally:
            # XÃ³a file táº¡m
            try:
                os.unlink(tmp_file_path)
            except Exception:
                pass

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi train Anomaly Detection System: {str(e)}")


@app.post("/check-anomaly")
async def check_anomaly(
    file: Optional[UploadFile] = File(None),
    indicators_json: Optional[str] = Form(None)
):
    """
    Endpoint kiá»ƒm tra báº¥t thÆ°á»ng cho DN má»›i

    Args:
        file: File Excel (náº¿u táº£i file má»›i) - Optional
        indicators_json: JSON string chá»©a 14 chá»‰ sá»‘ (náº¿u dÃ¹ng dá»¯ liá»‡u tá»« Tab Dá»± bÃ¡o PD) - Optional

    Returns:
        Dict chá»©a:
        - anomaly_score: Äiá»ƒm báº¥t thÆ°á»ng (0-100)
        - risk_level: Má»©c rá»§i ro
        - abnormal_features: List cÃ¡c features báº¥t thÆ°á»ng
        - anomaly_type: Loáº¡i báº¥t thÆ°á»ng
        - gemini_explanation: Giáº£i thÃ­ch tá»« Gemini AI
        - comparison_with_healthy: So sÃ¡nh vá»›i DN khá»e máº¡nh
    """
    try:
        import json

        # Kiá»ƒm tra Anomaly Detection System Ä‘Ã£ Ä‘Æ°á»£c train chÆ°a
        if anomaly_system.model is None:
            raise HTTPException(
                status_code=400,
                detail="Anomaly Detection System chÆ°a Ä‘Æ°á»£c train. Vui lÃ²ng upload file training data trÆ°á»›c."
            )

        # 1. Láº¤Y 14 CHá»ˆ Sá»
        indicators = {}

        if file:
            # TrÆ°á»ng há»£p 1: Táº£i file XLSX má»›i
            if not file.filename.endswith(('.xlsx', '.xls')):
                raise HTTPException(status_code=400, detail="File pháº£i cÃ³ Ä‘á»‹nh dáº¡ng XLSX hoáº·c XLS")

            # LÆ°u file táº¡m
            with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp_file:
                content = await file.read()
                tmp_file.write(content)
                tmp_file_path = tmp_file.name

            try:
                # Äá»c file XLSX vÃ  tÃ­nh 14 chá»‰ sá»‘
                excel_processor.read_excel(tmp_file_path)
                indicators = excel_processor.calculate_14_indicators()
            finally:
                try:
                    os.unlink(tmp_file_path)
                except Exception:
                    pass

        elif indicators_json:
            # TrÆ°á»ng há»£p 2: Sá»­ dá»¥ng dá»¯ liá»‡u tá»« Tab Dá»± bÃ¡o PD
            indicators = json.loads(indicators_json)
        else:
            raise HTTPException(
                status_code=400,
                detail="Vui lÃ²ng cung cáº¥p file XLSX hoáº·c dá»¯ liá»‡u tá»« Tab Dá»± bÃ¡o PD"
            )

        # 2. TÃNH ANOMALY SCORE
        anomaly_score = anomaly_system.calculate_anomaly_score(indicators)

        # 3. PHÃT HIá»†N CÃC FEATURES Báº¤T THÆ¯á»œNG
        abnormal_features = anomaly_system.detect_abnormal_features(indicators)

        # 4. PHÃ‚N LOáº I LOáº I Báº¤T THÆ¯á»œNG
        anomaly_type = anomaly_system.classify_anomaly_type(indicators, abnormal_features)

        # 5. XÃC Äá»ŠNH Má»¨C Rá»¦I RO
        if anomaly_score < 60:
            risk_level = "BÃ¬nh thÆ°á»ng"
            risk_level_color = "#10B981"
            risk_level_icon = "âš ï¸"
        elif anomaly_score < 80:
            risk_level = "Báº¥t thÆ°á»ng Trung bÃ¬nh"
            risk_level_color = "#F59E0B"
            risk_level_icon = "ğŸ”¶"
        else:
            risk_level = "Báº¥t thÆ°á»ng Cao"
            risk_level_color = "#EF4444"
            risk_level_icon = "ğŸ”´"

        # 6. Táº O GIáº¢I THÃCH Báº°NG GEMINI AI
        gemini_explanation = anomaly_system.generate_gemini_explanation(
            indicators=indicators,
            anomaly_score=anomaly_score,
            abnormal_features=abnormal_features,
            anomaly_type=anomaly_type,
            gemini_api_key=GEMINI_API_KEY
        )

        # 7. SO SÃNH Vá»šI DN KHá»E Máº NH (cho Radar Chart)
        comparison_with_healthy = []
        for feature in anomaly_system.feature_names:
            comparison_with_healthy.append({
                'feature': anomaly_system.indicator_names[feature],
                'current': indicators[feature],
                'healthy_mean': anomaly_system.healthy_stats[feature]['mean']
            })

        # 8. TRáº¢ Vá»€ Káº¾T QUáº¢
        response_data = {
            "status": "success",
            "anomaly_score": anomaly_score,
            "risk_level": risk_level,
            "risk_level_color": risk_level_color,
            "risk_level_icon": risk_level_icon,
            "abnormal_features": abnormal_features,
            "anomaly_type": anomaly_type,
            "gemini_explanation": gemini_explanation,
            "comparison_with_healthy": comparison_with_healthy,
            "indicators": indicators
        }

        return convert_to_json_serializable(response_data)

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi kiá»ƒm tra báº¥t thÆ°á»ng: {str(e)}")


# ================================================================================================
# SURVIVAL ANALYSIS ENDPOINTS
# ================================================================================================

@app.post("/train-survival")
async def train_survival_models(file: UploadFile = File(...)):
    """
    Huáº¥n luyá»‡n Survival Analysis Models (Cox PH + Random Survival Forest)
    Cháº¡y tuáº§n tá»± 2 mÃ´ hÃ¬nh Ä‘á»ƒ Ä‘áº£m báº£o á»•n Ä‘á»‹nh

    Input: CSV/Excel file vá»›i cá»™t:
    - X_1 Ä‘áº¿n X_14: 14 chá»‰ sá»‘ tÃ i chÃ­nh
    - months_to_default: Thá»i gian Ä‘áº¿n khi vá»¡ ná»£ (thÃ¡ng)
    - event: 1 = vá»¡ ná»£, 0 = censored (chÆ°a vá»¡ ná»£)

    Returns:
    - Training metrics (C-index, log-likelihood)
    - Kaplan-Meier baseline survival function (downsampled Ä‘á»ƒ giáº£m kÃ­ch thÆ°á»›c)
    - Hazard ratios
    """
    print("\n" + "="*80)
    print("ğŸš€ [SURVIVAL TRAINING] Báº¯t Ä‘áº§u huáº¥n luyá»‡n Cox PH & RSF models...")
    print("="*80)

    tmp_file_path = None

    try:
        # 1. LÆ¯U FILE Táº M THá»œI
        print("ğŸ“ [SURVIVAL TRAINING] Äang lÆ°u file táº¡m thá»i...")
        with tempfile.NamedTemporaryFile(delete=False, suffix=".csv") as tmp_file:
            tmp_file.write(await file.read())
            tmp_file_path = tmp_file.name
        print(f"âœ… [SURVIVAL TRAINING] ÄÃ£ lÆ°u file: {tmp_file_path}")

        try:
            # 2. Äá»ŒC Dá»® LIá»†U
            print("ğŸ“Š [SURVIVAL TRAINING] Äang Ä‘á»c dá»¯ liá»‡u...")
            if file.filename.endswith('.csv'):
                df = pd.read_csv(tmp_file_path)
            elif file.filename.endswith(('.xlsx', '.xls')):
                df = pd.read_excel(tmp_file_path)
            else:
                raise HTTPException(
                    status_code=400,
                    detail="File pháº£i lÃ  Ä‘á»‹nh dáº¡ng CSV hoáº·c Excel (.xlsx, .xls)"
                )

            print(f"âœ… [SURVIVAL TRAINING] ÄÃ£ Ä‘á»c {len(df)} dÃ²ng dá»¯ liá»‡u")

            # 3. KIá»‚M TRA Cá»˜T Cáº¦N THIáº¾T
            print("ğŸ” [SURVIVAL TRAINING] Äang kiá»ƒm tra cÃ¡c cá»™t dá»¯ liá»‡u...")
            required_features = [f'X_{i}' for i in range(1, 15)]
            required_cols = required_features + ['months_to_default']

            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                raise HTTPException(
                    status_code=400,
                    detail=f"Thiáº¿u cÃ¡c cá»™t: {', '.join(missing_cols)}"
                )

            # Náº¿u khÃ´ng cÃ³ cá»™t 'event', tá»± Ä‘á»™ng táº¡o (giáº£ Ä‘á»‹nh táº¥t cáº£ Ä‘á»u vá»¡ ná»£)
            if 'event' not in df.columns:
                df['event'] = 1
                print("âš ï¸  [SURVIVAL TRAINING] KhÃ´ng tÃ¬m tháº¥y cá»™t 'event', táº¡o tá»± Ä‘á»™ng (all events = 1)")

            print(f"âœ… [SURVIVAL TRAINING] Validation hoÃ n táº¥t. Events: {int(df['event'].sum())}, Censored: {int((1-df['event']).sum())}")

            # 4. HUáº¤N LUYá»†N TUáº¦N Tá»° (SEQUENTIAL) - ÄÆ N GIáº¢N VÃ€ á»”N Äá»ŠNH HÆ N
            print("\nâš¡ [SURVIVAL TRAINING] Äang huáº¥n luyá»‡n láº§n lÆ°á»£t Cox PH vÃ  RSF models...")
            cox_result = None
            rsf_result = None
            training_errors = []

            # 4.1. TRAIN COX PH MODEL TRÆ¯á»šC
            try:
                print("ğŸ”„ [COX MODEL - 1/2] Báº¯t Ä‘áº§u huáº¥n luyá»‡n Cox Proportional Hazards Model...")
                cox_result = survival_system.train_cox_model(
                    df,
                    duration_col='months_to_default',
                    event_col='event'
                )
                print(f"âœ… [COX MODEL - 1/2] HoÃ n thÃ nh! C-index: {cox_result['c_index']:.4f}")
            except Exception as e:
                print(f"âŒ [COX MODEL - 1/2] Lá»—i: {str(e)}")
                training_errors.append({
                    "model": "Cox PH",
                    "error": str(e)
                })

            # 4.2. TRAIN RSF MODEL SAU
            try:
                print("ğŸ”„ [RSF MODEL - 2/2] Báº¯t Ä‘áº§u huáº¥n luyá»‡n Random Survival Forest Model...")
                rsf_result = survival_system.train_random_survival_forest(
                    df,
                    duration_col='months_to_default',
                    event_col='event',
                    n_estimators=100
                )
                print(f"âœ… [RSF MODEL - 2/2] HoÃ n thÃ nh! C-index: {rsf_result['c_index']:.4f}")
            except Exception as e:
                print(f"âŒ [RSF MODEL - 2/2] Lá»—i: {str(e)}")
                training_errors.append({
                    "model": "RSF",
                    "error": str(e)
                })

            print("\n" + "="*80)
            print("ğŸ“Š [SURVIVAL TRAINING] Káº¿t quáº£ huáº¥n luyá»‡n tuáº§n tá»±:")
            print(f"   - Cox PH: {'âœ… ThÃ nh cÃ´ng' if cox_result else 'âŒ Tháº¥t báº¡i'}")
            print(f"   - RSF: {'âœ… ThÃ nh cÃ´ng' if rsf_result else 'âŒ Tháº¥t báº¡i'}")
            print("="*80)

            # 6. TÃNH KAPLAN-MEIER BASELINE (chá»‰ khi cÃ³ Ã­t nháº¥t 1 model thÃ nh cÃ´ng)
            km_result = None
            if cox_result or rsf_result:
                try:
                    print("ğŸ“ˆ [SURVIVAL TRAINING] Äang tÃ­nh Kaplan-Meier baseline...")
                    km_result = survival_system.calculate_kaplan_meier(
                        df,
                        duration_col='months_to_default',
                        event_col='event'
                    )

                    # Downsample KM data Ä‘á»ƒ giáº£m kÃ­ch thÆ°á»›c response
                    if km_result and 'timeline' in km_result:
                        original_points = len(km_result.get('timeline', []))
                        km_result = downsample_kaplan_meier(km_result, max_points=100)
                        print(f"âœ… [SURVIVAL TRAINING] Kaplan-Meier baseline Ä‘Ã£ tÃ­nh xong ({original_points} â†’ {len(km_result.get('timeline', []))} Ä‘iá»ƒm)")
                    else:
                        print("âœ… [SURVIVAL TRAINING] Kaplan-Meier baseline Ä‘Ã£ tÃ­nh xong")
                except Exception as e:
                    print(f"âš ï¸  [SURVIVAL TRAINING] KhÃ´ng thá»ƒ tÃ­nh Kaplan-Meier: {str(e)}")
                    km_result = {"error": str(e)}

            # 7. Láº¤Y HAZARD RATIOS (chá»‰ khi Cox model thÃ nh cÃ´ng)
            hazard_ratios = None
            if cox_result:
                try:
                    print("ğŸ“Š [SURVIVAL TRAINING] Äang tÃ­nh hazard ratios...")
                    hazard_ratios = survival_system.get_hazard_ratios(top_k=14)
                    print(f"âœ… [SURVIVAL TRAINING] ÄÃ£ tÃ­nh {len(hazard_ratios)} hazard ratios")
                except Exception as e:
                    print(f"âš ï¸  [SURVIVAL TRAINING] KhÃ´ng thá»ƒ tÃ­nh hazard ratios: {str(e)}")
                    hazard_ratios = []

            # 8. LÆ¯U MODELS (chá»‰ khi cÃ³ Ã­t nháº¥t 1 model thÃ nh cÃ´ng)
            if cox_result or rsf_result:
                try:
                    print("ğŸ’¾ [SURVIVAL TRAINING] Äang lÆ°u models...")
                    survival_system.save_models('survival_models.pkl')
                    print("âœ… [SURVIVAL TRAINING] Models Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o survival_models.pkl")
                except Exception as e:
                    print(f"âš ï¸  [SURVIVAL TRAINING] KhÃ´ng thá»ƒ lÆ°u models: {str(e)}")

            # 9. TRáº¢ Vá»€ Káº¾T QUáº¢ (JSON SERIALIZABLE)
            print("\n" + "="*80)
            print("ğŸ‰ [SURVIVAL TRAINING] HoÃ n thÃ nh quÃ¡ trÃ¬nh training!")
            print("="*80 + "\n")

            # Kiá»ƒm tra xem cÃ³ Ã­t nháº¥t 1 model thÃ nh cÃ´ng khÃ´ng
            if not cox_result and not rsf_result:
                raise HTTPException(
                    status_code=500,
                    detail=f"Cáº£ 2 models Ä‘á»u tháº¥t báº¡i. Errors: {training_errors}"
                )

            # Táº¡o response data vÃ  convert sang JSON serializable types
            response_data = {
                "status": "success",
                "message": "ÄÃ£ huáº¥n luyá»‡n thÃ nh cÃ´ng cÃ¡c mÃ´ hÃ¬nh Survival Analysis",
                "cox_model": cox_result if cox_result else {"status": "failed", "error": "Training failed"},
                "rsf_model": rsf_result if rsf_result else {"status": "failed", "error": "Training failed"},
                "kaplan_meier": km_result if km_result else {"status": "not_computed"},
                "hazard_ratios": hazard_ratios if hazard_ratios else [],
                "training_errors": training_errors,
                "n_samples": len(df),
                "n_events": int(df['event'].sum()),
                "n_censored": int((1 - df['event']).sum())
            }

            # Convert táº¥t cáº£ numpy/pandas types sang Python native types
            print("ğŸ”„ [SURVIVAL TRAINING] Äang serialize response data...")
            json_response = convert_to_json_serializable(response_data)

            # Log kÃ­ch thÆ°á»›c response (Æ°á»›c tÃ­nh)
            import json
            try:
                response_size = len(json.dumps(json_response))
                print(f"ğŸ“¦ [SURVIVAL TRAINING] Response size: {response_size:,} bytes ({response_size/1024:.2f} KB)")
            except Exception as e:
                print(f"âš ï¸  [SURVIVAL TRAINING] KhÃ´ng thá»ƒ tÃ­nh kÃ­ch thÆ°á»›c response: {str(e)}")

            print("âœ… [SURVIVAL TRAINING] Response Ä‘Ã£ sáºµn sÃ ng Ä‘á»ƒ gá»­i vá» frontend\n")

            # Sá»­ dá»¥ng JSONResponse explicitly Ä‘á»ƒ Ä‘áº£m báº£o serialize chÃ­nh xÃ¡c
            return JSONResponse(content=json_response)

        finally:
            # XÃ³a file táº¡m
            if tmp_file_path and os.path.exists(tmp_file_path):
                try:
                    os.unlink(tmp_file_path)
                    print(f"ğŸ—‘ï¸  [SURVIVAL TRAINING] ÄÃ£ xÃ³a file táº¡m: {tmp_file_path}")
                except Exception as e:
                    print(f"âš ï¸  [SURVIVAL TRAINING] KhÃ´ng thá»ƒ xÃ³a file táº¡m: {str(e)}")

    except HTTPException as e:
        print(f"âŒ [SURVIVAL TRAINING] HTTPException: {str(e)}")
        raise
    except Exception as e:
        print(f"âŒ [SURVIVAL TRAINING] Lá»—i khÃ´ng mong muá»‘n: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=500,
            detail=f"Lá»—i khi huáº¥n luyá»‡n survival models: {str(e)}"
        )


@app.post("/train-cox")
async def train_cox_model(file: UploadFile = File(...)):
    """
    Huáº¥n luyá»‡n riÃªng Cox Proportional Hazards Model
    (Endpoint Ä‘Æ¡n giáº£n hÆ¡n, chá»‰ train 1 model Ä‘á»ƒ trÃ¡nh lá»—i network)

    Input: CSV/Excel file vá»›i cá»™t:
    - X_1 Ä‘áº¿n X_14: 14 chá»‰ sá»‘ tÃ i chÃ­nh
    - months_to_default: Thá»i gian Ä‘áº¿n khi vá»¡ ná»£ (thÃ¡ng)
    - event: 1 = vá»¡ ná»£, 0 = censored (chÆ°a vá»¡ ná»£)

    Returns:
    - Cox Model training metrics (C-index, log-likelihood)
    - Kaplan-Meier baseline survival function
    - Hazard ratios
    """
    print("\n" + "="*80)
    print("ğŸš€ [COX TRAINING] Báº¯t Ä‘áº§u huáº¥n luyá»‡n Cox PH model...")
    print("="*80)

    tmp_file_path = None

    try:
        # 1. LÆ¯U FILE Táº M THá»œI
        print("ğŸ“ [COX TRAINING] Äang lÆ°u file táº¡m thá»i...")
        with tempfile.NamedTemporaryFile(delete=False, suffix=".csv") as tmp_file:
            tmp_file.write(await file.read())
            tmp_file_path = tmp_file.name
        print(f"âœ… [COX TRAINING] ÄÃ£ lÆ°u file: {tmp_file_path}")

        try:
            # 2. Äá»ŒC Dá»® LIá»†U
            print("ğŸ“Š [COX TRAINING] Äang Ä‘á»c dá»¯ liá»‡u...")
            if file.filename.endswith('.csv'):
                df = pd.read_csv(tmp_file_path)
            elif file.filename.endswith(('.xlsx', '.xls')):
                df = pd.read_excel(tmp_file_path)
            else:
                raise HTTPException(
                    status_code=400,
                    detail="File pháº£i lÃ  Ä‘á»‹nh dáº¡ng CSV hoáº·c Excel (.xlsx, .xls)"
                )

            print(f"âœ… [COX TRAINING] ÄÃ£ Ä‘á»c {len(df)} dÃ²ng dá»¯ liá»‡u")

            # 3. KIá»‚M TRA Cá»˜T Cáº¦N THIáº¾T
            print("ğŸ” [COX TRAINING] Äang kiá»ƒm tra cÃ¡c cá»™t dá»¯ liá»‡u...")
            required_features = [f'X_{i}' for i in range(1, 15)]
            required_cols = required_features + ['months_to_default']

            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                raise HTTPException(
                    status_code=400,
                    detail=f"Thiáº¿u cÃ¡c cá»™t: {', '.join(missing_cols)}"
                )

            # Náº¿u khÃ´ng cÃ³ cá»™t 'event', tá»± Ä‘á»™ng táº¡o
            if 'event' not in df.columns:
                df['event'] = 1
                print("âš ï¸  [COX TRAINING] KhÃ´ng tÃ¬m tháº¥y cá»™t 'event', táº¡o tá»± Ä‘á»™ng (all events = 1)")

            print(f"âœ… [COX TRAINING] Validation hoÃ n táº¥t. Events: {int(df['event'].sum())}, Censored: {int((1-df['event']).sum())}")

            # 4. HUáº¤N LUYá»†N COX MODEL
            print("ğŸ”„ [COX TRAINING] Äang huáº¥n luyá»‡n Cox Proportional Hazards Model...")
            cox_result = survival_system.train_cox_model(
                df,
                duration_col='months_to_default',
                event_col='event'
            )
            print(f"âœ… [COX TRAINING] HoÃ n thÃ nh! C-index: {cox_result['c_index']:.4f}")

            # 5. TÃNH KAPLAN-MEIER BASELINE
            km_result = None
            try:
                print("ğŸ“ˆ [COX TRAINING] Äang tÃ­nh Kaplan-Meier baseline...")
                km_result = survival_system.calculate_kaplan_meier(
                    df,
                    duration_col='months_to_default',
                    event_col='event'
                )

                # Downsample KM data
                if km_result and 'timeline' in km_result:
                    original_points = len(km_result.get('timeline', []))
                    km_result = downsample_kaplan_meier(km_result, max_points=100)
                    print(f"âœ… [COX TRAINING] Kaplan-Meier baseline Ä‘Ã£ tÃ­nh xong ({original_points} â†’ {len(km_result.get('timeline', []))} Ä‘iá»ƒm)")
            except Exception as e:
                print(f"âš ï¸  [COX TRAINING] KhÃ´ng thá»ƒ tÃ­nh Kaplan-Meier: {str(e)}")
                km_result = {"error": str(e)}

            # 6. Láº¤Y HAZARD RATIOS
            hazard_ratios = None
            try:
                print("ğŸ“Š [COX TRAINING] Äang tÃ­nh hazard ratios...")
                hazard_ratios = survival_system.get_hazard_ratios(top_k=14)
                print(f"âœ… [COX TRAINING] ÄÃ£ tÃ­nh {len(hazard_ratios)} hazard ratios")
            except Exception as e:
                print(f"âš ï¸  [COX TRAINING] KhÃ´ng thá»ƒ tÃ­nh hazard ratios: {str(e)}")
                hazard_ratios = []

            # 7. LÆ¯U MODEL
            try:
                print("ğŸ’¾ [COX TRAINING] Äang lÆ°u model...")
                survival_system.save_models('survival_models.pkl')
                print("âœ… [COX TRAINING] Model Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o survival_models.pkl")
            except Exception as e:
                print(f"âš ï¸  [COX TRAINING] KhÃ´ng thá»ƒ lÆ°u model: {str(e)}")

            # 8. Táº O RESPONSE
            print("\n" + "="*80)
            print("ğŸ‰ [COX TRAINING] HoÃ n thÃ nh quÃ¡ trÃ¬nh training!")
            print("="*80 + "\n")

            response_data = {
                "status": "success",
                "message": "ÄÃ£ huáº¥n luyá»‡n thÃ nh cÃ´ng Cox Proportional Hazards Model",
                "cox_model": cox_result,
                "kaplan_meier": km_result if km_result else {"status": "not_computed"},
                "hazard_ratios": hazard_ratios if hazard_ratios else [],
                "n_samples": len(df),
                "n_events": int(df['event'].sum()),
                "n_censored": int((1 - df['event']).sum())
            }

            # Convert sang JSON serializable
            print("ğŸ”„ [COX TRAINING] Äang serialize response data...")
            json_response = convert_to_json_serializable(response_data)

            # Log kÃ­ch thÆ°á»›c
            import json
            try:
                response_size = len(json.dumps(json_response))
                print(f"ğŸ“¦ [COX TRAINING] Response size: {response_size:,} bytes ({response_size/1024:.2f} KB)")
            except Exception as e:
                print(f"âš ï¸  [COX TRAINING] KhÃ´ng thá»ƒ tÃ­nh kÃ­ch thÆ°á»›c response: {str(e)}")

            print("âœ… [COX TRAINING] Response Ä‘Ã£ sáºµn sÃ ng Ä‘á»ƒ gá»­i vá» frontend\n")

            return JSONResponse(content=json_response)

        finally:
            # XÃ³a file táº¡m
            if tmp_file_path and os.path.exists(tmp_file_path):
                try:
                    os.unlink(tmp_file_path)
                    print(f"ğŸ—‘ï¸  [COX TRAINING] ÄÃ£ xÃ³a file táº¡m: {tmp_file_path}")
                except Exception as e:
                    print(f"âš ï¸  [COX TRAINING] KhÃ´ng thá»ƒ xÃ³a file táº¡m: {str(e)}")

    except HTTPException as e:
        print(f"âŒ [COX TRAINING] HTTPException: {str(e)}")
        raise
    except Exception as e:
        print(f"âŒ [COX TRAINING] Lá»—i khÃ´ng mong muá»‘n: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=500,
            detail=f"Lá»—i khi huáº¥n luyá»‡n Cox model: {str(e)}"
        )


@app.post("/train-rsf")
async def train_rsf_model(file: UploadFile = File(...)):
    """
    Huáº¥n luyá»‡n riÃªng Random Survival Forest Model
    (Endpoint Ä‘Æ¡n giáº£n hÆ¡n, chá»‰ train 1 model Ä‘á»ƒ trÃ¡nh lá»—i network)

    Input: CSV/Excel file vá»›i cá»™t:
    - X_1 Ä‘áº¿n X_14: 14 chá»‰ sá»‘ tÃ i chÃ­nh
    - months_to_default: Thá»i gian Ä‘áº¿n khi vá»¡ ná»£ (thÃ¡ng)
    - event: 1 = vá»¡ ná»£, 0 = censored (chÆ°a vá»¡ ná»£)

    Returns:
    - RSF Model training metrics (C-index)
    """
    print("\n" + "="*80)
    print("ğŸš€ [RSF TRAINING] Báº¯t Ä‘áº§u huáº¥n luyá»‡n Random Survival Forest model...")
    print("="*80)

    tmp_file_path = None

    try:
        # 1. LÆ¯U FILE Táº M THá»œI
        print("ğŸ“ [RSF TRAINING] Äang lÆ°u file táº¡m thá»i...")
        with tempfile.NamedTemporaryFile(delete=False, suffix=".csv") as tmp_file:
            tmp_file.write(await file.read())
            tmp_file_path = tmp_file.name
        print(f"âœ… [RSF TRAINING] ÄÃ£ lÆ°u file: {tmp_file_path}")

        try:
            # 2. Äá»ŒC Dá»® LIá»†U
            print("ğŸ“Š [RSF TRAINING] Äang Ä‘á»c dá»¯ liá»‡u...")
            if file.filename.endswith('.csv'):
                df = pd.read_csv(tmp_file_path)
            elif file.filename.endswith(('.xlsx', '.xls')):
                df = pd.read_excel(tmp_file_path)
            else:
                raise HTTPException(
                    status_code=400,
                    detail="File pháº£i lÃ  Ä‘á»‹nh dáº¡ng CSV hoáº·c Excel (.xlsx, .xls)"
                )

            print(f"âœ… [RSF TRAINING] ÄÃ£ Ä‘á»c {len(df)} dÃ²ng dá»¯ liá»‡u")

            # 3. KIá»‚M TRA Cá»˜T Cáº¦N THIáº¾T
            print("ğŸ” [RSF TRAINING] Äang kiá»ƒm tra cÃ¡c cá»™t dá»¯ liá»‡u...")
            required_features = [f'X_{i}' for i in range(1, 15)]
            required_cols = required_features + ['months_to_default']

            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                raise HTTPException(
                    status_code=400,
                    detail=f"Thiáº¿u cÃ¡c cá»™t: {', '.join(missing_cols)}"
                )

            # Náº¿u khÃ´ng cÃ³ cá»™t 'event', tá»± Ä‘á»™ng táº¡o
            if 'event' not in df.columns:
                df['event'] = 1
                print("âš ï¸  [RSF TRAINING] KhÃ´ng tÃ¬m tháº¥y cá»™t 'event', táº¡o tá»± Ä‘á»™ng (all events = 1)")

            print(f"âœ… [RSF TRAINING] Validation hoÃ n táº¥t. Events: {int(df['event'].sum())}, Censored: {int((1-df['event']).sum())}")

            # 4. HUáº¤N LUYá»†N RSF MODEL
            print("ğŸ”„ [RSF TRAINING] Äang huáº¥n luyá»‡n Random Survival Forest Model...")
            rsf_result = survival_system.train_random_survival_forest(
                df,
                duration_col='months_to_default',
                event_col='event',
                n_estimators=100
            )
            print(f"âœ… [RSF TRAINING] HoÃ n thÃ nh! C-index: {rsf_result['c_index']:.4f}")

            # 5. LÆ¯U MODEL
            try:
                print("ğŸ’¾ [RSF TRAINING] Äang lÆ°u model...")
                survival_system.save_models('survival_models.pkl')
                print("âœ… [RSF TRAINING] Model Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o survival_models.pkl")
            except Exception as e:
                print(f"âš ï¸  [RSF TRAINING] KhÃ´ng thá»ƒ lÆ°u model: {str(e)}")

            # 6. Táº O RESPONSE
            print("\n" + "="*80)
            print("ğŸ‰ [RSF TRAINING] HoÃ n thÃ nh quÃ¡ trÃ¬nh training!")
            print("="*80 + "\n")

            response_data = {
                "status": "success",
                "message": "ÄÃ£ huáº¥n luyá»‡n thÃ nh cÃ´ng Random Survival Forest Model",
                "rsf_model": rsf_result,
                "n_samples": len(df),
                "n_events": int(df['event'].sum()),
                "n_censored": int((1 - df['event']).sum())
            }

            # Convert sang JSON serializable
            print("ğŸ”„ [RSF TRAINING] Äang serialize response data...")
            json_response = convert_to_json_serializable(response_data)

            # Log kÃ­ch thÆ°á»›c
            import json
            try:
                response_size = len(json.dumps(json_response))
                print(f"ğŸ“¦ [RSF TRAINING] Response size: {response_size:,} bytes ({response_size/1024:.2f} KB)")
            except Exception as e:
                print(f"âš ï¸  [RSF TRAINING] KhÃ´ng thá»ƒ tÃ­nh kÃ­ch thÆ°á»›c response: {str(e)}")

            print("âœ… [RSF TRAINING] Response Ä‘Ã£ sáºµn sÃ ng Ä‘á»ƒ gá»­i vá» frontend\n")

            return JSONResponse(content=json_response)

        finally:
            # XÃ³a file táº¡m
            if tmp_file_path and os.path.exists(tmp_file_path):
                try:
                    os.unlink(tmp_file_path)
                    print(f"ğŸ—‘ï¸  [RSF TRAINING] ÄÃ£ xÃ³a file táº¡m: {tmp_file_path}")
                except Exception as e:
                    print(f"âš ï¸  [RSF TRAINING] KhÃ´ng thá»ƒ xÃ³a file táº¡m: {str(e)}")

    except HTTPException as e:
        print(f"âŒ [RSF TRAINING] HTTPException: {str(e)}")
        raise
    except Exception as e:
        print(f"âŒ [RSF TRAINING] Lá»—i khÃ´ng mong muá»‘n: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=500,
            detail=f"Lá»—i khi huáº¥n luyá»‡n RSF model: {str(e)}"
        )


@app.post("/predict-survival")
async def predict_survival(
    file: Optional[UploadFile] = File(None),
    indicators_json: Optional[str] = Form(None)
):
    """
    Dá»± bÃ¡o Survival Curve cho má»™t doanh nghiá»‡p má»›i

    Input:
    - file: XLSX file (3 sheets: CDKT, BCTN, LCTT)
    - indicators_json: JSON string vá»›i 14 chá»‰ sá»‘

    Returns:
    - Survival curve (timeline + probabilities)
    - Median time-to-default
    - Survival probabilities táº¡i 6/12/24 thÃ¡ng
    - Risk classification
    - Hazard ratios (top 5 quan trá»ng nháº¥t) - Model-level metrics
    - Risk contributions (top 5) - Individual-level metrics cho doanh nghiá»‡p nÃ y
    """
    try:
        import json

        # 1. Láº¤Y 14 CHá»ˆ Sá» TÃ€I CHÃNH
        if file:
            # Tá»« file XLSX
            with tempfile.NamedTemporaryFile(delete=False, suffix=".xlsx") as tmp_file:
                tmp_file.write(await file.read())
                tmp_file_path = tmp_file.name

            try:
                excel_processor.read_excel(tmp_file_path)
                indicators = excel_processor.calculate_14_indicators()
            finally:
                try:
                    os.unlink(tmp_file_path)
                except Exception:
                    pass

        elif indicators_json:
            # Tá»« JSON
            indicators = json.loads(indicators_json)
        else:
            raise HTTPException(
                status_code=400,
                detail="Vui lÃ²ng cung cáº¥p file XLSX hoáº·c dá»¯ liá»‡u 14 chá»‰ sá»‘"
            )

        # 2. KIá»‚M TRA MODEL ÄÃƒ ÄÆ¯á»¢C HUáº¤N LUYá»†N
        if survival_system.cox_model is None:
            raise HTTPException(
                status_code=400,
                detail="MÃ´ hÃ¬nh chÆ°a Ä‘Æ°á»£c huáº¥n luyá»‡n. Vui lÃ²ng gá»i /train-survival trÆ°á»›c."
            )

        # 3. Dá»° BÃO SURVIVAL CURVE (sá»­ dá»¥ng Cox model)
        survival_curve = survival_system.predict_survival_curve(
            indicators=indicators,
            model_type='cox'
        )

        # 4. TÃNH MEDIAN TIME-TO-DEFAULT
        median_time = survival_system.calculate_median_time_to_default(
            indicators=indicators,
            model_type='cox'
        )

        # 5. TÃNH SURVIVAL PROBABILITIES Táº I CÃC THá»œI ÄIá»‚M Cá»¤ THá»‚
        survival_probs = survival_system.get_survival_probabilities_at_times(
            indicators=indicators,
            times=[6, 12, 24],
            model_type='cox'
        )

        # 6. PHÃ‚N LOáº I Rá»¦I RO
        risk_info = survival_system.get_risk_classification(median_time)

        # 7. Láº¤Y HAZARD RATIOS (TOP 5) - Model-level metrics
        hazard_ratios = survival_system.get_hazard_ratios(top_k=5)

        # 8. Láº¤Y INDIVIDUAL RISK CONTRIBUTIONS (TOP 5) - Cá»¤ THá»‚ CHO DOANH NGHIá»†P NÃ€Y
        # KHÃC vá»›i hazard ratios (model-level, giá»‘ng nhau cho má»i DN)
        risk_contributions = survival_system.get_individual_risk_contributions(
            indicators=indicators,
            top_k=5
        )

        # 9. Táº O Cáº¢NH BÃO Náº¾U Rá»¦I RO CAO
        warning = None
        if median_time < 12:
            warning = {
                'type': 'HIGH_RISK',
                'message': f'âš ï¸ Cáº¢NH BÃO: Median time-to-default chá»‰ {median_time:.1f} thÃ¡ng! Doanh nghiá»‡p cÃ³ nguy cÆ¡ vá»¡ ná»£ ráº¥t cao.',
                'recommendation': 'NgÃ¢n hÃ ng nÃªn tá»« chá»‘i cho vay hoáº·c yÃªu cáº§u tÃ i sáº£n tháº¿ cháº¥p bá»• sung.'
            }
        elif median_time < 18:
            warning = {
                'type': 'MEDIUM_RISK',
                'message': f'âš ï¸ LÆ¯U Ã: Median time-to-default lÃ  {median_time:.1f} thÃ¡ng. Cáº§n theo dÃµi cháº·t cháº½.',
                'recommendation': 'Xem xÃ©t háº¡n má»©c tÃ­n dá»¥ng tháº¥p hÆ¡n vÃ  yÃªu cáº§u bÃ¡o cÃ¡o tÃ i chÃ­nh Ä‘á»‹nh ká»³.'
            }

        response_data = {
            "status": "success",
            "indicators": indicators,
            "survival_curve": survival_curve,
            "median_time_to_default": float(median_time),
            "survival_probabilities": survival_probs,
            "risk_classification": risk_info,
            "hazard_ratios": hazard_ratios,  # Model-level (giá»‘ng cho má»i DN)
            "risk_contributions": risk_contributions,  # Cá»¤ THá»‚ cho doanh nghiá»‡p nÃ y
            "warning": warning
        }

        return convert_to_json_serializable(response_data)

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Lá»—i khi dá»± bÃ¡o survival: {str(e)}"
        )


@app.get("/survival-metrics")
async def get_survival_metrics():
    """
    Láº¥y cÃ¡c metrics vÃ  hazard ratios tá»« trained models

    Returns:
    - Cox model metrics (C-index, log-likelihood)
    - RSF model metrics
    - Hazard ratios cho táº¥t cáº£ 14 chá»‰ sá»‘
    - Kaplan-Meier baseline survival
    """
    try:
        # Kiá»ƒm tra model Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n
        if survival_system.cox_model is None:
            raise HTTPException(
                status_code=400,
                detail="MÃ´ hÃ¬nh chÆ°a Ä‘Æ°á»£c huáº¥n luyá»‡n. Vui lÃ²ng gá»i /train-survival trÆ°á»›c."
            )

        # Láº¥y hazard ratios (táº¥t cáº£ 14 chá»‰ sá»‘)
        hazard_ratios = survival_system.get_hazard_ratios(top_k=14)

        # Láº¥y Kaplan-Meier baseline
        km_baseline = survival_system.calculate_kaplan_meier()

        response_data = {
            "status": "success",
            "metrics": survival_system.metrics,
            "hazard_ratios": hazard_ratios,
            "kaplan_meier_baseline": km_baseline
        }

        return convert_to_json_serializable(response_data)

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Lá»—i khi láº¥y survival metrics: {str(e)}"
        )


@app.post("/analyze-survival-gemini")
async def analyze_survival_gemini(
    data: Dict[str, Any]
):
    """
    PhÃ¢n tÃ­ch káº¿t quáº£ Survival Analysis báº±ng Gemini AI

    Input:
    - data: Dict chá»©a survival analysis results

    Returns:
    - Dict vá»›i analysis text tá»« Gemini
    """
    try:
        # Láº¥y data tá»« request
        survival_data = data.get('data', {})

        # PhÃ¢n tÃ­ch báº±ng Gemini
        analyzer = get_gemini_analyzer(GEMINI_API_KEY)
        analysis = analyzer.analyze_survival_results(survival_data)

        response_data = {
            "status": "success",
            "analysis": analysis
        }

        return convert_to_json_serializable(response_data)

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Lá»—i khi phÃ¢n tÃ­ch survival báº±ng Gemini: {str(e)}"
        )


@app.post("/export-survival-report")
async def export_survival_report(
    data: Dict[str, Any]
):
    """
    Xuáº¥t bÃ¡o cÃ¡o Survival Analysis ra file Word

    Input:
    - data: Dict chá»©a survival analysis results vÃ  Gemini analysis

    Returns:
    - File Word bÃ¡o cÃ¡o
    """
    try:
        # Táº¡o tÃªn file unique
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"Bao_cao_Survival_Analysis_{timestamp}.docx"
        filepath = os.path.join(tempfile.gettempdir(), filename)

        # Táº¡o bÃ¡o cÃ¡o
        report_path = report_generator.generate_survival_report(data, filepath)

        # Tráº£ vá» file
        return FileResponse(
            path=report_path,
            filename=filename,
            media_type="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
        )

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Lá»—i khi xuáº¥t bÃ¡o cÃ¡o: {str(e)}"
        )


# ================================================================================================
# MAIN
# ================================================================================================

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
